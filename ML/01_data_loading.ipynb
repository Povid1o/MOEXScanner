{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö OHLCV, –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ log_returns –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±–∞–∑–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞.  \n",
        "\n",
        "**–ö–ª—é—á–µ–≤—ã–µ –∑–∞–¥–∞—á–∏:**\n",
        "- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ MOEX\n",
        "- –ß–∏—Å—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ —Å–ø–ª–∏—Ç-–¥–∞—Ç\n",
        "- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ log_returns –±–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ –¥–∏–≤–∏–¥–µ–Ω–¥–∞–º/–∫–æ—Ä–ø. –¥–µ–π—Å—Ç–≤–∏—è–º (–ø–æ —Ä–µ—à–µ–Ω–∏—é)\n",
        "- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º: e:\\Python\\VolatilityChecker\\MOEXScanner\\ML\\data\\MOEX_DATA\n",
            "–ù–∞–π–¥–µ–Ω–æ: True\n"
          ]
        }
      ],
      "source": [
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
        "current_dir = Path.cwd()\n",
        "DATA_DIR = current_dir / \"data\" / \"MOEX_DATA\"\n",
        "\n",
        "# –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö –≤ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö\n",
        "if not DATA_DIR.exists():\n",
        "    alt_path = current_dir.parent / \"ML\" / \"data\" / \"MOEX_DATA\"\n",
        "    if alt_path.exists():\n",
        "        DATA_DIR = alt_path\n",
        "    else:\n",
        "        for parent in [current_dir, current_dir.parent]:\n",
        "            test_path = parent / \"data\" / \"MOEX_DATA\"\n",
        "            if test_path.exists():\n",
        "                DATA_DIR = test_path\n",
        "                break\n",
        "\n",
        "print(f\"–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º: {DATA_DIR}\")\n",
        "print(f\"–ù–∞–π–¥–µ–Ω–æ: {DATA_DIR.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§—É–Ω–∫—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ä–∞—Å—á–µ—Ç–∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ –§—É–Ω–∫—Ü–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n"
          ]
        }
      ],
      "source": [
        "def calculate_log_returns(prices):\n",
        "    \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏: log(P_t / P_{t-1})\"\"\"\n",
        "    if not isinstance(prices, pd.Series):\n",
        "        prices = pd.Series(prices)\n",
        "    log_prices = np.log(prices)\n",
        "    return log_prices - log_prices.shift(1)\n",
        "\n",
        "\n",
        "def load_ticker_data(ticker, data_dir=DATA_DIR, timeframe='1D'):\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–∫–µ—Ä—É –∏–∑ CSV\"\"\"\n",
        "    ticker_dir = data_dir / ticker / timeframe\n",
        "    if not ticker_dir.exists():\n",
        "        raise FileNotFoundError(f\"–ü–∞–ø–∫–∞ {ticker_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")\n",
        "    \n",
        "    csv_files = list(ticker_dir.glob(\"*.csv\"))\n",
        "    if not csv_files:\n",
        "        raise FileNotFoundError(f\"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {ticker_dir}\")\n",
        "    \n",
        "    df = pd.read_csv(csv_files[0])\n",
        "    \n",
        "    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç\n",
        "    if 'end' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['end'])\n",
        "    elif 'begin' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['begin'])\n",
        "    \n",
        "    df = df.sort_values('date').reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —Ç–∏–∫–µ—Ä–µ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "–¢–∏–∫–µ—Ä: SBER\n",
            "–ü–µ—Ä–∏–æ–¥: 2020-10-12 ‚Üí 2025-10-11\n",
            "–ó–∞–ø–∏—Å–µ–π: 1302\n",
            "\n",
            "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ log returns:\n",
            "count    1301.000000\n",
            "mean        0.000247\n",
            "std         0.023760\n",
            "min        -0.455918\n",
            "25%        -0.007616\n",
            "50%         0.000539\n",
            "75%         0.009146\n",
            "max         0.117686\n",
            "Name: log_return, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —Ç–∏–∫–µ—Ä–µ\n",
        "ticker = 'SBER'\n",
        "df = load_ticker_data(ticker, timeframe='1D')\n",
        "df['log_return'] = calculate_log_returns(df['close'])\n",
        "\n",
        "print(f\"\\n–¢–∏–∫–µ—Ä: {ticker}\")\n",
        "print(f\"–ü–µ—Ä–∏–æ–¥: {df['date'].min().date()} ‚Üí {df['date'].max().date()}\")\n",
        "print(f\"–ó–∞–ø–∏—Å–µ–π: {len(df)}\")\n",
        "print(f\"\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ log returns:\")\n",
        "print(df['log_return'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∏–∫–µ—Ä–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ SBER: 1301 –∑–∞–ø–∏—Å–µ–π\n",
            "‚úÖ GAZP: 1301 –∑–∞–ø–∏—Å–µ–π\n",
            "‚úÖ LKOH: 1301 –∑–∞–ø–∏—Å–µ–π\n",
            "‚úÖ MTSS: 1300 –∑–∞–ø–∏—Å–µ–π\n",
            "‚úÖ YNDX: 356 –∑–∞–ø–∏—Å–µ–π\n",
            "‚úÖ ROSN: 1301 –∑–∞–ø–∏—Å–µ–π\n",
            "‚úÖ GMKN: 1297 –∑–∞–ø–∏—Å–µ–π\n",
            "\n",
            "–¢–∏–∫–µ—Ä  –ó–∞–ø–∏—Å–µ–π   –°—Ä–µ–¥–Ω–µ–µ  –°—Ç.–æ—Ç–∫–ª.\n",
            " SBER     1301  0.000247  0.023760\n",
            " GAZP     1301 -0.000293  0.026512\n",
            " LKOH     1301  0.000228  0.019893\n",
            " MTSS     1300 -0.000382  0.020580\n",
            " YNDX      356 -0.000228  0.019620\n",
            " ROSN     1301  0.000045  0.023672\n",
            " GMKN     1297 -0.000337  0.019813\n"
          ]
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∏–∫–µ—Ä–æ–≤\n",
        "test_tickers = ['SBER', 'GAZP', 'LKOH', 'MTSS', 'YNDX', 'ROSN', 'GMKN']\n",
        "results = {}\n",
        "\n",
        "for ticker in test_tickers:\n",
        "    try:\n",
        "        df = load_ticker_data(ticker, timeframe='1D')\n",
        "        df['log_return'] = calculate_log_returns(df['close'])\n",
        "        \n",
        "        # –ß–∏—Å—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
        "        df = df.dropna(subset=['close', 'log_return'])\n",
        "        \n",
        "        results[ticker] = df\n",
        "        print(f\"‚úÖ {ticker}: {len(df)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {ticker}: {e}\")\n",
        "\n",
        "# –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
        "if results:\n",
        "    summary = pd.DataFrame({\n",
        "        '–¢–∏–∫–µ—Ä': list(results.keys()),\n",
        "        '–ó–∞–ø–∏—Å–µ–π': [len(results[k]) for k in results.keys()],\n",
        "        '–°—Ä–µ–¥–Ω–µ–µ': [results[k]['log_return'].mean() for k in results.keys()],\n",
        "        '–°—Ç.–æ—Ç–∫–ª.': [results[k]['log_return'].std() for k in results.keys()],\n",
        "    })\n",
        "    print(f\"\\n{summary.to_string(index=False)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "–°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —ç—Ç–∞–ø–æ–≤ Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\processed\\SBER_ohlcv_returns.parquet\n",
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\processed\\GAZP_ohlcv_returns.parquet\n",
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\processed\\LKOH_ohlcv_returns.parquet\n",
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\processed\\MTSS_ohlcv_returns.parquet\n",
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\processed\\YNDX_ohlcv_returns.parquet\n",
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\processed\\ROSN_ohlcv_returns.parquet\n",
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\processed\\GMKN_ohlcv_returns.parquet\n",
            "\n",
            "üìÅ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data\\processed\n"
          ]
        }
      ],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "OUTPUT_DIR = Path('data') / 'processed'\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for ticker, df in results.items():\n",
        "    output_path = OUTPUT_DIR / f\"{ticker}_ohlcv_returns.parquet\"\n",
        "    df.to_parquet(output_path, index=False)\n",
        "    print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\")\n",
        "\n",
        "print(f\"\\nüìÅ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {OUTPUT_DIR}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
