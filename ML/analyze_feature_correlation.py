"""
üìä –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –º–æ–¥–µ–ª–∏

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ processed_ml/, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö –∏ —Å—Ç—Ä–æ–∏—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
–¥–ª—è –≤—Å–µ—Ö —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –≥—Ä—É–ø–ø–∏—Ä—É—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.

–ó–∞–ø—É—Å–∫:
    python analyze_feature_correlation.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys
from typing import List, Dict, Tuple
import warnings
warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
ML_ROOT = Path(__file__).parent
sys.path.insert(0, str(ML_ROOT))

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
try:
    from config.training_config import EXCLUDE_TICKERS
except ImportError:
    EXCLUDE_TICKERS = []


# === –ö–ê–¢–ï–ì–û–†–ò–ò –ü–†–ò–ó–ù–ê–ö–û–í ===
FEATURE_CATEGORIES = {
    'volatility': [
        'volatility', 'realized_vol', 'garch', 'atr', 'parkinson', 'garman_klass',
        'rvol', 'rv', 'vol_ratio', 'volatility_ratio'
    ],
    'volume': [
        'volume', 'vol_zscore', 'vol_ratio', 'vp_', 'volume_profile', 
        'volume_spike', 'vp_above_va'
    ],
    'trend': [
        'rsi', 'momentum', 'dist_to_ma', 'dist_to_sma', 'dist_to_ema',
        'trend_signal', 'trend_strength', 'price_position'
    ],
    'calendar': [
        'day_of_week', 'day_of_month', 'is_month', 'overnight_gap',
        'calendar', 'weekday', 'month'
    ],
    'market': [
        'beta', 'correlation', 'index_vol', 'market', 'imoex'
    ],
    'intraday': [
        'intraday', 'hourly', 'h1_', 'range_', 'spread', 'tick_volume',
        'intraday_vol', 'intraday_range'
    ],
    'metadata': [
        'ticker_id', 'sector_id', 'sector_encoded', 'liquidity_rank',
        'is_blue_chip', 'lot_size'
    ]
}


def categorize_feature(feature_name: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø—Ä–∏–∑–Ω–∞–∫–∞ –ø–æ –∏–º–µ–Ω–∏."""
    feature_lower = feature_name.lower()
    
    for category, keywords in FEATURE_CATEGORIES.items():
        if any(keyword in feature_lower for keyword in keywords):
            return category
    
    return 'other'


def load_all_features(data_dir: Path) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã *_ml_features.parquet –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤ –æ–¥–∏–Ω DataFrame.
    
    Args:
        data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å parquet —Ñ–∞–π–ª–∞–º–∏
        
    Returns:
        pd.DataFrame: –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤
    """
    print("=" * 70)
    print("üì• –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    print("=" * 70)
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã
    files = list(data_dir.glob("*_ml_features.parquet"))
    
    if not files:
        raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –≤ {data_dir}")
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã (—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏—Å–∫–ª—é—á—ë–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤)
    dfs = []
    excluded_count = 0
    
    for f in files:
        ticker = f.stem.replace('_ml_features', '')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–∫–ª—é—á—ë–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä—ã
        if ticker in EXCLUDE_TICKERS:
            print(f"   ‚è≠Ô∏è {ticker}: –ò–°–ö–õ–Æ–ß–Å–ù")
            excluded_count += 1
            continue
        
        df = pd.read_parquet(f)
        print(f"   ‚Ä¢ {ticker}: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        dfs.append(df)
    
    if excluded_count:
        print(f"\n‚ö†Ô∏è –ò—Å–∫–ª—é—á–µ–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {excluded_count}")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω DataFrame
    global_df = pd.concat(dfs, ignore_index=True)
    print(f"\nüìä –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(global_df):,} —Å—Ç—Ä–æ–∫, {len(global_df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
    
    return global_df


def prepare_features_for_correlation(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, List[str]]]:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    
    –ò—Å–∫–ª—é—á–∞–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.
    
    Args:
        df: –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
        
    Returns:
        Tuple[feature_df, feature_categories]:
        - feature_df: DataFrame —Ç–æ–ª—å–∫–æ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - feature_categories: –°–ª–æ–≤–∞—Ä—å {–∫–∞—Ç–µ–≥–æ—Ä–∏—è: [—Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]}
    """
    print("\n" + "=" * 70)
    print("üîß –ü–û–î–ì–û–¢–û–í–ö–ê –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 70)
    
    # –°–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    exclude_cols = [
        'date', 'ticker_id', 'sector_id',  # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        'target_vol_1d', 'target_vol_5d', 'target_vol_10d', 'target_vol_20d',  # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    ]
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    numeric_cols = []
    for col in feature_cols:
        if df[col].dtype in ['float32', 'float64', 'int32', 'int64']:
            numeric_cols.append(col)
        elif df[col].dtype.name == 'category':
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–∂–Ω–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å, –Ω–æ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ª—É—á—à–µ –∏—Å–∫–ª—é—á–∏—Ç—å
            continue
    
    print(f"üìã –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")
    print(f"üìã –ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(numeric_cols)}")
    print(f"üìã –ò—Å–∫–ª—é—á–µ–Ω–æ —Å–ª—É–∂–µ–±–Ω—ã—Ö: {len(df.columns) - len(numeric_cols)}")
    
    # –°–æ–∑–¥–∞—ë–º DataFrame —Ç–æ–ª—å–∫–æ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    feature_df = df[numeric_cols].copy()
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    feature_df = feature_df.replace([np.inf, -np.inf], np.nan)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    feature_categories = {}
    for col in numeric_cols:
        category = categorize_feature(col)
        if category not in feature_categories:
            feature_categories[category] = []
        feature_categories[category].append(col)
    
    print(f"\nüìä –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for category, features in sorted(feature_categories.items()):
        print(f"   ‚Ä¢ {category}: {len(features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    return feature_df, feature_categories


def calculate_correlation_matrix(feature_df: pd.DataFrame) -> pd.DataFrame:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É.
    
    Args:
        feature_df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        
    Returns:
        pd.DataFrame: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    """
    print("\n" + "=" * 70)
    print("üìä –†–ê–°–ß–Å–¢ –ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–û–ô –ú–ê–¢–†–ò–¶–´")
    print("=" * 70)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
    corr_matrix = feature_df.corr(method='pearson')
    
    print(f"‚úÖ –†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã: {corr_matrix.shape}")
    print(f"üìà –î–∏–∞–ø–∞–∑–æ–Ω –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π: [{corr_matrix.min().min():.3f}, {corr_matrix.max().max():.3f}]")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º (–∏—Å–∫–ª—é—á–∞—è –¥–∏–∞–≥–æ–Ω–∞–ª—å)
    mask = ~np.eye(corr_matrix.shape[0], dtype=bool)
    correlations = corr_matrix.values[mask]
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–±–µ–∑ –¥–∏–∞–≥–æ–Ω–∞–ª–∏):")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ: {np.mean(correlations):.3f}")
    print(f"   ‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {np.median(correlations):.3f}")
    print(f"   ‚Ä¢ Std: {np.std(correlations):.3f}")
    print(f"   ‚Ä¢ Min: {np.min(correlations):.3f}")
    print(f"   ‚Ä¢ Max: {np.max(correlations):.3f}")
    
    # –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (>0.7 –∏–ª–∏ <-0.7)
    strong_pos = np.sum(correlations > 0.7)
    strong_neg = np.sum(correlations < -0.7)
    print(f"\nüîç –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (|r| > 0.7):")
    print(f"   ‚Ä¢ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ (>0.7): {strong_pos}")
    print(f"   ‚Ä¢ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ (<-0.7): {strong_neg}")
    
    return corr_matrix


def find_high_correlations(corr_matrix: pd.DataFrame, threshold: float = 0.7) -> pd.DataFrame:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –ø–∞—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π.
    
    Args:
        corr_matrix: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        
    Returns:
        pd.DataFrame: –¢–∞–±–ª–∏—Ü–∞ —Å –ø–∞—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∏—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º–∏
    """
    high_corr_pairs = []
    
    for i in range(len(corr_matrix.columns)):
        for j in range(i + 1, len(corr_matrix.columns)):
            corr_value = corr_matrix.iloc[i, j]
            if abs(corr_value) >= threshold:
                high_corr_pairs.append({
                    'feature_1': corr_matrix.columns[i],
                    'feature_2': corr_matrix.columns[j],
                    'correlation': corr_value,
                    'abs_correlation': abs(corr_value)
                })
    
    if high_corr_pairs:
        high_corr_df = pd.DataFrame(high_corr_pairs)
        high_corr_df = high_corr_df.sort_values('abs_correlation', ascending=False)
        return high_corr_df
    else:
        return pd.DataFrame(columns=['feature_1', 'feature_2', 'correlation', 'abs_correlation'])


def plot_correlation_heatmap(
    corr_matrix: pd.DataFrame,
    feature_categories: Dict[str, List[str]],
    output_dir: Path,
    max_features: int = 100
):
    """
    –°—Ç—Ä–æ–∏—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.
    
    Args:
        corr_matrix: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        feature_categories: –°–ª–æ–≤–∞—Ä—å –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        max_features: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    """
    print("\n" + "=" * 70)
    print("üé® –ü–û–°–¢–†–û–ï–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô")
    print("=" * 70)
    
    # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ, –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø –ø–æ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
    if len(corr_matrix) > max_features:
        print(f"‚ö†Ô∏è –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ ({len(corr_matrix)}), –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-{max_features}...")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ (std)
        variances = corr_matrix.std(axis=1)
        top_features = variances.nlargest(max_features).index.tolist()
        
        corr_matrix = corr_matrix.loc[top_features, top_features]
        print(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ {len(corr_matrix)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è –ª—É—á—à–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    category_order = ['volatility', 'volume', 'trend', 'calendar', 'market', 'intraday', 'metadata', 'other']
    sorted_features = []
    used_features = set()
    
    for category in category_order:
        if category in feature_categories:
            for feat in feature_categories[category]:
                if feat in corr_matrix.columns and feat not in used_features:
                    sorted_features.append(feat)
                    used_features.add(feat)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è
    for feat in corr_matrix.columns:
        if feat not in used_features:
            sorted_features.append(feat)
    
    corr_matrix_sorted = corr_matrix.loc[sorted_features, sorted_features]
    
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–≥—É—Ä—É
    fig, ax = plt.subplots(figsize=(20, 18))
    
    # –°—Ç—Ä–æ–∏–º heatmap
    sns.heatmap(
        corr_matrix_sorted,
        cmap='coolwarm',
        center=0,
        vmin=-1,
        vmax=1,
        square=True,
        fmt='.2f',
        cbar_kws={'label': '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞'},
        ax=ax,
        linewidths=0.5,
        linecolor='gray'
    )
    
    ax.set_title(
        f'–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–¥–µ–ª–∏\n'
        f'–í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(corr_matrix_sorted)}',
        fontsize=16,
        pad=20
    )
    ax.set_xlabel('–ü—Ä–∏–∑–Ω–∞–∫–∏', fontsize=12)
    ax.set_ylabel('–ü—Ä–∏–∑–Ω–∞–∫–∏', fontsize=12)
    
    # –ü–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∏
    plt.xticks(rotation=90, ha='right', fontsize=8)
    plt.yticks(rotation=0, fontsize=8)
    
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_path = output_dir / 'feature_correlation_heatmap.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    
    plt.close()


def plot_correlation_by_category(
    corr_matrix: pd.DataFrame,
    feature_categories: Dict[str, List[str]],
    output_dir: Path
):
    """
    –°—Ç—Ä–æ–∏—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –≤–Ω—É—Ç—Ä–∏ –∏ –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏.
    
    Args:
        corr_matrix: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        feature_categories: –°–ª–æ–≤–∞—Ä—å –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    print("\nüìä –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º...")
    
    category_order = ['volatility', 'volume', 'trend', 'calendar', 'market', 'intraday', 'metadata', 'other']
    
    # –°—Ç—Ä–æ–∏–º –º–∞—Ç—Ä–∏—Ü—É —Å—Ä–µ–¥–Ω–∏—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
    category_corr = pd.DataFrame(
        index=category_order,
        columns=category_order,
        dtype=float
    )
    
    for cat1 in category_order:
        for cat2 in category_order:
            if cat1 not in feature_categories or cat2 not in feature_categories:
                category_corr.loc[cat1, cat2] = np.nan
                continue
            
            features1 = [f for f in feature_categories[cat1] if f in corr_matrix.columns]
            features2 = [f for f in feature_categories[cat2] if f in corr_matrix.columns]
            
            if not features1 or not features2:
                category_corr.loc[cat1, cat2] = np.nan
                continue
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            submatrix = corr_matrix.loc[features1, features2]
            
            if cat1 == cat2:
                # –í–Ω—É—Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: –∏—Å–∫–ª—é—á–∞–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å
                mask = ~np.eye(len(submatrix), dtype=bool)
                values = submatrix.values[mask]
            else:
                # –ú–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏: –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è
                values = submatrix.values.flatten()
            
            category_corr.loc[cat1, cat2] = np.nanmean(values)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    fig, ax = plt.subplots(figsize=(12, 10))
    
    sns.heatmap(
        category_corr,
        annot=True,
        fmt='.3f',
        cmap='coolwarm',
        center=0,
        vmin=-1,
        vmax=1,
        square=True,
        cbar_kws={'label': '–°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è'},
        ax=ax,
        linewidths=1,
        linecolor='black'
    )
    
    ax.set_title(
        '–°—Ä–µ–¥–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤',
        fontsize=14,
        pad=20
    )
    ax.set_xlabel('–ö–∞—Ç–µ–≥–æ—Ä–∏—è', fontsize=12)
    ax.set_ylabel('–ö–∞—Ç–µ–≥–æ—Ä–∏—è', fontsize=12)
    
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    
    output_path = output_dir / 'feature_correlation_by_category.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    
    plt.close()
    
    return category_corr


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("\n" + "üöÄ" * 35)
    print("   –ê–ù–ê–õ–ò–ó –ö–û–†–†–ï–õ–Ø–¶–ò–ô –ü–†–ò–ó–ù–ê–ö–û–í –ú–û–î–ï–õ–ò")
    print("   " + pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("üöÄ" * 35)
    
    # –ü—É—Ç–∏
    data_dir = ML_ROOT / "data" / "processed_ml"
    output_dir = ML_ROOT / "reports"
    output_dir.mkdir(exist_ok=True)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_all_features(data_dir)
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_df, feature_categories = prepare_features_for_correlation(df)
    
    # 3. –†–∞—Å—á—ë—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
    corr_matrix = calculate_correlation_matrix(feature_df)
    
    # 4. –ü–æ–∏—Å–∫ –≤—ã—Å–æ–∫–∏—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
    print("\n" + "=" * 70)
    print("üîç –ü–û–ò–°–ö –í–´–°–û–ö–ò–• –ö–û–†–†–ï–õ–Ø–¶–ò–ô")
    print("=" * 70)
    
    high_corr = find_high_correlations(corr_matrix, threshold=0.7)
    
    if len(high_corr) > 0:
        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä —Å |r| >= 0.7: {len(high_corr)}")
        print("\n–¢–æ–ø-20 —Å–∞–º—ã—Ö —Å–∏–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π:")
        print("-" * 80)
        print(high_corr.head(20).to_string(index=False))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        high_corr_path = output_dir / 'high_correlations.csv'
        high_corr.to_csv(high_corr_path, index=False)
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {high_corr_path}")
    else:
        print("‚úÖ –í—ã—Å–æ–∫–∏—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (|r| >= 0.7) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã...")
    corr_matrix_path = output_dir / 'feature_correlation_matrix.csv'
    corr_matrix.to_csv(corr_matrix_path)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {corr_matrix_path}")
    
    # 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    plot_correlation_heatmap(corr_matrix, feature_categories, output_dir, max_features=100)
    category_corr = plot_correlation_by_category(corr_matrix, feature_categories, output_dir)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_corr_path = output_dir / 'feature_correlation_by_category.csv'
    category_corr.to_csv(category_corr_path)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {category_corr_path}")
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 70)
    print("üèÅ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù")
    print("=" * 70)
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
    print(f"   ‚Ä¢ feature_correlation_matrix.csv - –ø–æ–ª–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")
    print(f"   ‚Ä¢ feature_correlation_heatmap.png - —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞")
    print(f"   ‚Ä¢ feature_correlation_by_category.png - –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
    print(f"   ‚Ä¢ feature_correlation_by_category.csv - —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
    if len(high_corr) > 0:
        print(f"   ‚Ä¢ high_correlations.csv - –ø–∞—Ä—ã —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π")
    print()


if __name__ == "__main__":
    main()

