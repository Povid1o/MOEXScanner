{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –ú–æ–¥–µ–ª—å GARCH(1,1) Skewed-t\n",
        "\n",
        "- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ returns\n",
        "- –ü—Ä–æ–≥–Ω–æ–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (—Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ)\n",
        "- Tail risk\n",
        "\n",
        "–®–∞–±–ª–æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞, –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã (arch –¥–æ—Å—Ç—É–ø–µ–Ω)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ arch –¥–ª—è GARCH\n",
        "try:\n",
        "    from arch import arch_model\n",
        "    print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã (arch –¥–æ—Å—Ç—É–ø–µ–Ω)\")\n",
        "    ARCH_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'arch' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install arch\")\n",
        "    ARCH_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ 0 —Ç–∏–∫–µ—Ä–æ–≤: []\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "DATA_DIR = Path('../02_feature_engineering/data/features')\n",
        "\n",
        "# –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
        "all_files = list(DATA_DIR.glob(\"*_with_targets.parquet\"))\n",
        "tickers = [f.stem.replace(\"_with_targets\", \"\") for f in all_files]\n",
        "\n",
        "# –í–∞—Ä–∏–∞–Ω—Ç 2: –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ metadata (–±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω—ã–π —Å–ø–æ—Å–æ–±)\n",
        "# with open(Path('../config/tickers_metadata.json'), 'r') as f:\n",
        "#     metadata = json.load(f)\n",
        "# tickers = [k for k in metadata.keys() if not k.startswith('_')]\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Å–ª–æ–≤–∞—Ä—å\n",
        "all_data = {}\n",
        "for ticker in tickers:\n",
        "    file_path = DATA_DIR / f\"{ticker}_with_targets.parquet\"\n",
        "    if file_path.exists():\n",
        "        df = pd.read_parquet(file_path)\n",
        "        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è GARCH\n",
        "        returns = df['log_return'].dropna() * 100  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "        all_data[ticker] = {\n",
        "            'df': df,\n",
        "            'returns': returns\n",
        "        }\n",
        "        print(f\"‚úÖ {ticker}: {len(returns)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π, mean={returns.mean():.4f}, std={returns.std():.4f}\")\n",
        "\n",
        "print(f\"\\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_data)} —Ç–∏–∫–µ—Ä–æ–≤: {list(all_data.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ GARCH(1,1) –º–æ–¥–µ–ª–∏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ARCH_AVAILABLE:\n",
        "    garch_models = {}\n",
        "    \n",
        "    for ticker, data in all_data.items():\n",
        "        returns = data['returns']\n",
        "        \n",
        "        # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º GARCH(1,1) –º–æ–¥–µ–ª—å —Å Skewed-t —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º\n",
        "        model = arch_model(returns, vol='Garch', p=1, q=1, dist='skewt', rescale=False)\n",
        "        \n",
        "        try:\n",
        "            fitted_model = model.fit(disp='off', show_warning=False)\n",
        "            \n",
        "            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Å–ª–æ–≤–Ω–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "            conditional_vol = fitted_model.conditional_volatility\n",
        "            \n",
        "            # –ü—Ä–æ–≥–Ω–æ–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ 1 —à–∞–≥ –≤–ø–µ—Ä–µ–¥\n",
        "            forecast = fitted_model.forecast(horizon=1)\n",
        "            forecast_variance = forecast.variance.iloc[-1, 0]\n",
        "            forecast_vol = np.sqrt(forecast_variance)\n",
        "            \n",
        "            garch_models[ticker] = {\n",
        "                'model': fitted_model,\n",
        "                'conditional_vol': conditional_vol,\n",
        "                'forecast_vol': forecast_vol\n",
        "            }\n",
        "            print(f\"‚úÖ {ticker}: –ø—Ä–æ–≥–Ω–æ–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ = {forecast_vol:.4f}%\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå {ticker}: –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è - {e}\")\n",
        "    \n",
        "    print(f\"\\nüìä –£—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(garch_models)}/{len(all_data)}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå GARCH –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É 'arch'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Walk-forward –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ARCH_AVAILABLE:\n",
        "    # Walk-forward –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 100 –¥–Ω—è—Ö\n",
        "    train_size = len(returns) - 100\n",
        "    forecasts = []\n",
        "    \n",
        "    print(\"Walk-forward –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...\")\n",
        "    \n",
        "    for i in range(train_size, len(returns)):\n",
        "        train_data = returns.iloc[:i]\n",
        "        \n",
        "        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–º –æ–∫–Ω–µ\n",
        "        model_temp = arch_model(train_data, vol='Garch', p=1, q=1, dist='skewt', rescale=False)\n",
        "        res_temp = model_temp.fit(disp='off', show_warning=False, update_freq=0)\n",
        "        \n",
        "        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 1 —à–∞–≥\n",
        "        forecast_temp = res_temp.forecast(horizon=1)\n",
        "        forecasts.append(np.sqrt(forecast_temp.variance.iloc[-1, 0]))\n",
        "    \n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã –≤ DataFrame\n",
        "    forecast_dates = df['date'].iloc[-100:]\n",
        "    forecast_df = pd.DataFrame({\n",
        "        'date': forecast_dates.values,\n",
        "        'garch_forecast': forecasts\n",
        "    })\n",
        "    \n",
        "    print(f\"‚úÖ Walk-forward –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(forecasts)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\")\n",
        "    print(forecast_df.tail())\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Walk-forward –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –±–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ 'arch'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ARCH_AVAILABLE:\n",
        "    OUTPUT_DIR = Path('data') / 'models'\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n",
        "    output_path = OUTPUT_DIR / f\"{ticker}_garch_forecasts.parquet\"\n",
        "    forecast_df.to_parquet(output_path, index=False)\n",
        "    \n",
        "    print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è –ù–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –±–µ–∑ GARCH –º–æ–¥–µ–ª–∏\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
