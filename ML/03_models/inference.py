"""
–ú–æ–¥—É–ª—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è –æ–±—É—á–µ–Ω–Ω—ã—Ö –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π LightGBM.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –ó–∞–≥—Ä—É–∑–∫–∏ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ [q16, q84]

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    from inference import GlobalQuantileModel
    
    model = GlobalQuantileModel()
    model.load_models()
    
    predictions = model.predict(new_data)
    # predictions —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫–∏: pred_q16, pred_q50, pred_q84
"""

import numpy as np
import pandas as pd
import lightgbm as lgb
from pathlib import Path
from typing import Dict, Optional, List
import warnings

warnings.filterwarnings('ignore')


class GlobalQuantileModel:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω—ã—Ö –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
    
    –ê—Ç—Ä–∏–±—É—Ç—ã:
        models: Dict[float, lgb.Booster] - —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º
        feature_names: List[str] - —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, model_dir: Optional[Path] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è.
        
        Args:
            model_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        """
        if model_dir is None:
            self.model_dir = Path(__file__).parent.parent / "data" / "models"
        else:
            self.model_dir = Path(model_dir)
        
        self.models: Dict[float, lgb.Booster] = {}
        self.feature_names: List[str] = []
        self.quantiles = [0.16, 0.50, 0.84]
        self._loaded = False
    
    def load_models(self) -> None:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
        
        Raises:
            FileNotFoundError: –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        """
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
        
        for alpha in self.quantiles:
            filename = f"global_lgbm_q{int(alpha*100)}.txt"
            path = self.model_dir / filename
            
            if not path.exists():
                raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {path}")
            
            self.models[alpha] = lgb.Booster(model_file=str(path))
            print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞: {filename}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
        self.feature_names = self.models[0.50].feature_name()
        self._loaded = True
        
        print(f"üìã –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {len(self.feature_names)}")
    
    def predict(
        self, 
        X: pd.DataFrame, 
        return_interval: bool = True
    ) -> pd.DataFrame:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å feature_names)
            return_interval: –ï—Å–ª–∏ True, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–∫–∂–µ —à–∏—Ä–∏–Ω—É –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            
        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: pred_q16, pred_q50, pred_q84, [interval_width]
        """
        if not self._loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –í—ã–∑–æ–≤–∏—Ç–µ load_models() —Å–Ω–∞—á–∞–ª–∞.")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        missing_features = set(self.feature_names) - set(X.columns)
        if missing_features:
            warnings.warn(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_prepared = X[self.feature_names].copy() if set(self.feature_names).issubset(X.columns) else X.copy()
        X_prepared = X_prepared.fillna(0)
        
        # –ü—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–≤–∞–Ω—Ç–∏–ª—è
        predictions = pd.DataFrame(index=X.index)
        
        for alpha in self.quantiles:
            col_name = f"pred_q{int(alpha*100)}"
            predictions[col_name] = self.models[alpha].predict(X_prepared)
        
        # –®–∏—Ä–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (–º–µ—Ä–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏)
        if return_interval:
            predictions['interval_width'] = predictions['pred_q84'] - predictions['pred_q16']
        
        return predictions
    
    def predict_with_confidence(
        self, 
        X: pd.DataFrame
    ) -> Dict:
        """
        –ü—Ä–æ–≥–Ω–æ–∑ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
        
        Args:
            X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            
        Returns:
            Dict —Å –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        """
        preds = self.predict(X, return_interval=True)
        
        return {
            'median': preds['pred_q50'].values,
            'lower': preds['pred_q16'].values,
            'upper': preds['pred_q84'].values,
            'interval_width': preds['interval_width'].values,
            'mean_uncertainty': preds['interval_width'].mean()
        }
    
    def get_feature_importance(
        self, 
        importance_type: str = 'gain',
        top_n: int = 20
    ) -> pd.DataFrame:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–µ–¥–∏–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
        
        Args:
            importance_type: 'gain' –∏–ª–∏ 'split'
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        if not self._loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–¥–∏–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        model = self.models[0.50]
        importance = model.feature_importance(importance_type=importance_type)
        
        imp_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        return imp_df.head(top_n)


def load_and_predict(
    data_path: Path,
    model_dir: Optional[Path] = None
) -> pd.DataFrame:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ñ–∞–π–ª–µ –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        data_path: –ü—É—Ç—å –∫ parquet —Ñ–∞–π–ª—É —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        model_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—è–º–∏
        
    Returns:
        DataFrame —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_parquet(data_path)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = GlobalQuantileModel(model_dir)
    model.load_models()
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    predictions = model.predict(df)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
    result = pd.concat([df, predictions], axis=1)
    
    return result


# === –≠–ö–°–ü–û–†–¢ ===
__all__ = [
    'GlobalQuantileModel',
    'load_and_predict'
]


if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
    print("üöÄ –¢–µ—Å—Ç –º–æ–¥—É–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    
    model = GlobalQuantileModel()
    
    try:
        model.load_models()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        ML_ROOT = Path(__file__).parent.parent
        test_file = list((ML_ROOT / "data" / "processed_ml").glob("*_ml_features.parquet"))[0]
        
        print(f"\nüìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞: {test_file.name}")
        df = pd.read_parquet(test_file)
        
        predictions = model.predict(df.head(100))
        print(f"\nüìà –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:")
        print(predictions.head())
        
        print(f"\nüìä Feature Importance (—Ç–æ–ø-10):")
        print(model.get_feature_importance(top_n=10))
        
    except FileNotFoundError as e:
        print(f"‚ùå {e}")
        print("   –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª–∏: python train_global_model.py")

