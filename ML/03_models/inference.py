"""
–ú–æ–¥—É–ª—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –ó–∞–≥—Ä—É–∑–∫–∏ –æ–±—É—á–µ–Ω–Ω—ã—Ö –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π LightGBM
- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ [q16, q84]
- –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ (LightGBM + GARCH)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ LightGBM):
    from inference import GlobalQuantileModel
    
    model = GlobalQuantileModel()
    model.load_models()
    
    predictions = model.predict(new_data)
    
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (–∞–Ω—Å–∞–º–±–ª—å LightGBM + GARCH):
    model = GlobalQuantileModel(use_ensemble=True)
    model.load_models()
    
    predictions = model.predict_ensemble(new_data)
    # predictions —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫–∏: pred_q16, pred_q50, pred_q84, ensemble_*
"""

import numpy as np
import pandas as pd
import lightgbm as lgb
from pathlib import Path
from typing import Dict, Optional, List, Union
import warnings
import sys

warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ models/
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from models.ensemble import EnsembleModel, SimpleGARCH, EnsembleWeights
    ENSEMBLE_AVAILABLE = True
except ImportError:
    ENSEMBLE_AVAILABLE = False
    warnings.warn("–ú–æ–¥—É–ª—å ensemble –Ω–µ –Ω–∞–π–¥–µ–Ω. –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")


class GlobalQuantileModel:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω—ã—Ö –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –ß–∏—Å—Ç—ã–π LightGBM –ø—Ä–æ–≥–Ω–æ–∑ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    - –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑ LightGBM + GARCH (use_ensemble=True)
    
    –ê—Ç—Ä–∏–±—É—Ç—ã:
        models: Dict[float, lgb.Booster] - —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º
        feature_names: List[str] - —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–¥–µ–ª–∏
        ensemble: EnsembleModel - –∞–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        garch: SimpleGARCH - GARCH –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è
    """
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å train_global_model.py)
    CATEGORICAL_FEATURES = [
        'ticker_id', 
        'sector_id',
        'is_month_end',
        'is_month_start',
        'day_of_week',
        'vp_above_va',
        'volume_spike',
        'trend_signal',
        'price_position_ma'
    ]
    
    def __init__(
        self, 
        model_dir: Optional[Path] = None,
        use_ensemble: bool = False,
        ensemble_weights: Optional[Dict[str, float]] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è.
        
        Args:
            model_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
            use_ensemble: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∞–Ω—Å–∞–º–±–ª—å —Å GARCH
            ensemble_weights: –í–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª—è {'lgbm': 0.7, 'garch': 0.3}
        """
        if model_dir is None:
            self.model_dir = Path(__file__).parent.parent / "data" / "models"
        else:
            self.model_dir = Path(model_dir)
        
        self.models: Dict[float, lgb.Booster] = {}
        self.feature_names: List[str] = []
        self.quantiles = [0.16, 0.50, 0.84]
        self._loaded = False
        
        # –ê–Ω—Å–∞–º–±–ª—å
        self.use_ensemble = use_ensemble and ENSEMBLE_AVAILABLE
        self.ensemble: Optional['EnsembleModel'] = None
        self.garch: Optional['SimpleGARCH'] = None
        
        if self.use_ensemble:
            if ensemble_weights is None:
                ensemble_weights = {'lgbm': 0.7, 'garch': 0.3}
            self.ensemble = EnsembleModel(weights=ensemble_weights)
            self.garch = SimpleGARCH()
            print(f"üì¶ –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π —Ä–µ–∂–∏–º: LightGBM ({ensemble_weights['lgbm']}) + GARCH ({ensemble_weights['garch']})")
        elif use_ensemble and not ENSEMBLE_AVAILABLE:
            warnings.warn("–ê–Ω—Å–∞–º–±–ª—å –∑–∞–ø—Ä–æ—à–µ–Ω, –Ω–æ –º–æ–¥—É–ª—å ensemble –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ LightGBM.")
    
    def load_models(self) -> None:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
        
        Raises:
            FileNotFoundError: –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        """
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
        
        for alpha in self.quantiles:
            filename = f"global_lgbm_q{int(alpha*100)}.txt"
            path = self.model_dir / filename
            
            if not path.exists():
                raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {path}")
            
            self.models[alpha] = lgb.Booster(model_file=str(path))
            print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞: {filename}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
        self.feature_names = self.models[0.50].feature_name()
        self._loaded = True
        
        print(f"üìã –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {len(self.feature_names)}")
    
    def predict(
        self, 
        X: pd.DataFrame, 
        return_interval: bool = True
    ) -> pd.DataFrame:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å feature_names)
            return_interval: –ï—Å–ª–∏ True, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–∫–∂–µ —à–∏—Ä–∏–Ω—É –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            
        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: pred_q16, pred_q50, pred_q84, [interval_width]
        """
        if not self._loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –í—ã–∑–æ–≤–∏—Ç–µ load_models() —Å–Ω–∞—á–∞–ª–∞.")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        missing_features = set(self.feature_names) - set(X.columns)
        if missing_features:
            warnings.warn(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_prepared = X[self.feature_names].copy() if set(self.feature_names).issubset(X.columns) else X.copy()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ category —Ç–∏–ø
        # –ö–†–ò–¢–ò–ß–ù–û: LightGBM —Ç—Ä–µ–±—É–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ train –∏ predict
        for col in self.CATEGORICAL_FEATURES:
            if col in X_prepared.columns:
                X_prepared[col] = X_prepared[col].astype('category')
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN —Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        numeric_cols = X_prepared.select_dtypes(include=[np.number]).columns
        X_prepared[numeric_cols] = X_prepared[numeric_cols].fillna(0)
        
        # –ü—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–≤–∞–Ω—Ç–∏–ª—è
        predictions = pd.DataFrame(index=X.index)
        
        for alpha in self.quantiles:
            col_name = f"pred_q{int(alpha*100)}"
            predictions[col_name] = self.models[alpha].predict(X_prepared)
        
        # –®–∏—Ä–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (–º–µ—Ä–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏)
        if return_interval:
            predictions['interval_width'] = predictions['pred_q84'] - predictions['pred_q16']
        
        return predictions
    
    def predict_ensemble(
        self,
        X: pd.DataFrame,
        returns: Optional[pd.Series] = None,
        return_components: bool = False
    ) -> pd.DataFrame:
        """
        –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑: LightGBM + GARCH.
        
        Args:
            X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è LightGBM
            returns: Series —Å log returns –¥–ª—è GARCH (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ X['log_return'])
            return_components: –ï—Å–ª–∏ True, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–∫–∂–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (lgbm, garch –æ—Ç–¥–µ–ª—å–Ω–æ)
            
        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:
                - pred_q16, pred_q50, pred_q84: –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã
                - interval_width: —à–∏—Ä–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
                - (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) lgbm_q50, garch_forecast: –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        """
        if not self.use_ensemble or self.ensemble is None:
            warnings.warn("–ê–Ω—Å–∞–º–±–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ LightGBM –ø—Ä–æ–≥–Ω–æ–∑.")
            return self.predict(X)
        
        if not self._loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –í—ã–∑–æ–≤–∏—Ç–µ load_models() —Å–Ω–∞—á–∞–ª–∞.")
        
        # 1. –ü—Ä–æ–≥–Ω–æ–∑ LightGBM
        lgbm_predictions = self.predict(X, return_interval=True)
        
        # 2. –ü—Ä–æ–≥–Ω–æ–∑ GARCH
        if returns is None:
            if 'log_return' in X.columns:
                returns = X['log_return']
            else:
                warnings.warn("log_return –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö. GARCH –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω—É–ª–∏.")
                returns = pd.Series(np.zeros(len(X)), index=X.index)
        
        # –ü–æ–¥–≥–æ–Ω—è–µ–º GARCH –∏ –¥–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
        returns_arr = returns.values
        
        # Rolling GARCH –ø—Ä–æ–≥–Ω–æ–∑
        garch_forecasts = self.garch.forecast_rolling(returns_arr, window=20)
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –º–µ–¥–∏–∞–Ω–æ–π LightGBM –¥–ª—è –ø–µ—Ä–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        nan_mask = np.isnan(garch_forecasts)
        if nan_mask.any():
            garch_forecasts[nan_mask] = lgbm_predictions['pred_q50'].values[nan_mask]
        
        # 3. –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –∞–Ω—Å–∞–º–±–ª—å
        ensemble_predictions = self.ensemble.predict(
            lgbm_predictions,
            garch_forecasts
        )
        
        # 4. –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if return_components:
            ensemble_predictions['lgbm_q50'] = lgbm_predictions['pred_q50']
            ensemble_predictions['garch_forecast'] = garch_forecasts
        
        return ensemble_predictions
    
    def predict_with_uncertainty_ensemble(
        self,
        X: pd.DataFrame,
        returns: Optional[pd.Series] = None
    ) -> Dict:
        """
        –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏.
        
        Args:
            X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            returns: Series —Å log returns –¥–ª—è GARCH
            
        Returns:
            Dict —Å –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:
                - median: –º–µ–¥–∏–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
                - lower, upper: –≥—Ä–∞–Ω–∏—Ü—ã –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
                - interval_width: —à–∏—Ä–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
                - model_agreement: —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å LightGBM –∏ GARCH (0-1)
                - weights_used: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª—è
        """
        if not self.use_ensemble or self.ensemble is None:
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π predict_with_confidence
            return self.predict_with_confidence(X)
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        lgbm_preds = self.predict(X, return_interval=True)
        
        if returns is None and 'log_return' in X.columns:
            returns = X['log_return']
        elif returns is None:
            returns = pd.Series(np.zeros(len(X)), index=X.index)
        
        garch_forecasts = self.garch.forecast_rolling(returns.values, window=20)
        nan_mask = np.isnan(garch_forecasts)
        if nan_mask.any():
            garch_forecasts[nan_mask] = lgbm_preds['pred_q50'].values[nan_mask]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ ensemble –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        result = self.ensemble.predict_with_uncertainty(
            lgbm_preds,
            garch_forecasts
        )
        
        return result
    
    def predict_with_confidence(
        self, 
        X: pd.DataFrame
    ) -> Dict:
        """
        –ü—Ä–æ–≥–Ω–æ–∑ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
        
        Args:
            X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            
        Returns:
            Dict —Å –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        """
        preds = self.predict(X, return_interval=True)
        
        return {
            'median': preds['pred_q50'].values,
            'lower': preds['pred_q16'].values,
            'upper': preds['pred_q84'].values,
            'interval_width': preds['interval_width'].values,
            'mean_uncertainty': preds['interval_width'].mean()
        }
    
    def get_feature_importance(
        self, 
        importance_type: str = 'gain',
        top_n: int = 20
    ) -> pd.DataFrame:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–µ–¥–∏–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
        
        Args:
            importance_type: 'gain' –∏–ª–∏ 'split'
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        if not self._loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–¥–∏–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        model = self.models[0.50]
        importance = model.feature_importance(importance_type=importance_type)
        
        imp_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        return imp_df.head(top_n)


def load_and_predict(
    data_path: Path,
    model_dir: Optional[Path] = None
) -> pd.DataFrame:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ñ–∞–π–ª–µ –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        data_path: –ü—É—Ç—å –∫ parquet —Ñ–∞–π–ª—É —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        model_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—è–º–∏
        
    Returns:
        DataFrame —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_parquet(data_path)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = GlobalQuantileModel(model_dir)
    model.load_models()
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    predictions = model.predict(df)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
    result = pd.concat([df, predictions], axis=1)
    
    return result


# === –≠–ö–°–ü–û–†–¢ ===
__all__ = [
    'GlobalQuantileModel',
    'load_and_predict',
    'ENSEMBLE_AVAILABLE'
]


if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
    print("üöÄ –¢–µ—Å—Ç –º–æ–¥—É–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    print(f"   –ê–Ω—Å–∞–º–±–ª—å –¥–æ—Å—Ç—É–ø–µ–Ω: {ENSEMBLE_AVAILABLE}")
    
    # –¢–µ—Å—Ç 1: –¢–æ–ª—å–∫–æ LightGBM
    print("\n" + "="*50)
    print("üì¶ –¢–ï–°–¢ 1: LightGBM")
    print("="*50)
    
    model = GlobalQuantileModel()
    
    try:
        model.load_models()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        ML_ROOT = Path(__file__).parent.parent
        test_file = list((ML_ROOT / "data" / "processed_ml").glob("*_ml_features.parquet"))[0]
        
        print(f"\nüìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞: {test_file.name}")
        df = pd.read_parquet(test_file)
        
        predictions = model.predict(df.head(100))
        print(f"\nüìà LightGBM –ø—Ä–æ–≥–Ω–æ–∑—ã:")
        print(predictions.head())
        
        print(f"\nüìä Feature Importance (—Ç–æ–ø-10):")
        print(model.get_feature_importance(top_n=10))
        
        # –¢–µ—Å—Ç 2: –ê–Ω—Å–∞–º–±–ª—å (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if ENSEMBLE_AVAILABLE:
            print("\n" + "="*50)
            print("üì¶ –¢–ï–°–¢ 2: –ê–Ω—Å–∞–º–±–ª—å LightGBM + GARCH")
            print("="*50)
            
            ensemble_model = GlobalQuantileModel(
                use_ensemble=True,
                ensemble_weights={'lgbm': 0.7, 'garch': 0.3}
            )
            ensemble_model.load_models()
            
            # –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑
            ensemble_preds = ensemble_model.predict_ensemble(
                df.head(100),
                return_components=True
            )
            print(f"\nüìà –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã:")
            print(ensemble_preds.head())
            
            # –° –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å—é
            uncertainty = ensemble_model.predict_with_uncertainty_ensemble(df.head(100))
            print(f"\nüìä Model Agreement: {uncertainty['model_agreement']:.3f}")
            print(f"   Weights: {uncertainty['weights_used']}")
        
    except FileNotFoundError as e:
        print(f"‚ùå {e}")
        print("   –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª–∏: python train_global_model.py")

