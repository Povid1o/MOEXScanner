{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
        "\n",
        "- –¶–µ–ª–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏: realized volatility horizon, spike_flag, quantiles\n",
        "- –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è target'–æ–≤, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
        "\n",
        "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è ML-–∑–∞–¥–∞—á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–º–µ—â–µ–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§—É–Ω–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_realized_vol_target(returns, horizon=5):\n",
        "    \"\"\"\n",
        "    –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ\n",
        "    –°–¥–≤–∏–≥ –Ω–∞ –±—É–¥—É—â–µ–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "    \"\"\"\n",
        "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ 'horizon' –¥–Ω–µ–π\n",
        "    target = returns.rolling(window=horizon).std().shift(-horizon) * np.sqrt(252)\n",
        "    return target\n",
        "\n",
        "\n",
        "def create_spike_flag(returns, threshold=2.0, window=20):\n",
        "    \"\"\"\n",
        "    –ë–∏–Ω–∞—Ä–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è: –±—É–¥–µ—Ç –ª–∏ –≤—Å–ø–ª–µ—Å–∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "    1 = –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞, 0 = –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
        "    \"\"\"\n",
        "    # –†–∞—Å—á–µ—Ç z-score –Ω–∞ –±—É–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥\n",
        "    future_returns = returns.shift(-1)\n",
        "    ma = returns.rolling(window=window).mean()\n",
        "    std = returns.rolling(window=window).std()\n",
        "    z_score = np.abs((future_returns - ma) / std)\n",
        "    \n",
        "    spike = (z_score > threshold).astype(int)\n",
        "    return spike\n",
        "\n",
        "\n",
        "def create_quantile_targets(returns, horizon=5, quantiles=[0.16, 0.50, 0.84]):\n",
        "    \"\"\"\n",
        "    –ö–≤–∞–Ω—Ç–∏–ª–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –±—É–¥—É—â–∏—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π\n",
        "    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è quantile regression\n",
        "    \"\"\"\n",
        "    targets = {}\n",
        "    for q in quantiles:\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º –∫–≤–∞–Ω—Ç–∏–ª—å –Ω–∞ —Å–∫–æ–ª—å–∑—è—â–µ–º –æ–∫–Ω–µ –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "        target = returns.rolling(window=horizon).quantile(q).shift(-horizon)\n",
        "        targets[f\"quantile_{int(q*100)}\"] = target\n",
        "    \n",
        "    return pd.DataFrame(targets)\n",
        "\n",
        "\n",
        "def create_directional_target(returns, horizon=1):\n",
        "    \"\"\"\n",
        "    –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è: 1 = –≤–≤–µ—Ä—Ö, 0 = –≤–Ω–∏–∑\n",
        "    –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "    \"\"\"\n",
        "    future_return = returns.shift(-horizon)\n",
        "    direction = (future_return > 0).astype(int)\n",
        "    return direction\n",
        "\n",
        "\n",
        "def create_all_targets(df, horizons=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è DataFrame\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # –¶–µ–ª–µ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—Ö\n",
        "    for h in horizons:\n",
        "        df[f\"target_vol_{h}d\"] = create_realized_vol_target(df[\"log_return\"], horizon=h)\n",
        "    \n",
        "    # –°–ø–∞–π–∫ —Ñ–ª–∞–≥\n",
        "    df[\"target_spike\"] = create_spike_flag(df[\"log_return\"], threshold=2.0, window=20)\n",
        "    \n",
        "    # –ö–≤–∞–Ω—Ç–∏–ª–∏\n",
        "    quantile_df = create_quantile_targets(df[\"log_return\"], horizon=5, quantiles=[0.16, 0.50, 0.84])\n",
        "    df = pd.concat([df, quantile_df], axis=1)\n",
        "    \n",
        "    # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ\n",
        "    df[\"target_direction\"] = create_directional_target(df[\"log_return\"], horizon=1)\n",
        "    \n",
        "    return df\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
        "current_dir = Path.cwd()\n",
        "print(f\"–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}\")\n",
        "\n",
        "# –°—Ç—Ä–æ–∏–º –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
        "DATA_DIR = current_dir.parent.parent / \"ML\" / \"data\" / \"processed\"\n",
        "OUTPUT_DIR = Path(\"data\") / \"features\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º: {DATA_DIR}\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø—É—Ç–∏\n",
        "if DATA_DIR.exists():\n",
        "    print(\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–∞–π–¥–µ–Ω–∞!\")\n",
        "else:\n",
        "    print(\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å\")\n",
        "\n",
        "# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –≤–∫–ª—é—á–∞—è –∏–Ω–¥–µ–∫—Å MOEX\n",
        "TICKERS = [\n",
        "    \"AFKS\", \"AFLT\", \"ALRS\", \"BELU\", \"BSPB\", \"CHMF\", \"FIVE\", \"GAZP\", \"GMKN\", \"HYDR\",\n",
        "    \"IMOEX\",  # –ò–Ω–¥–µ–∫—Å –ú–æ—Å–±–∏—Ä–∂–∏\n",
        "    \"IRAO\", \"LENT\", \"LKOH\", \"MAGN\", \"MGNT\", \"MTSS\", \"NLMK\", \"NVTK\", \"OZON\",\n",
        "    \"PIKK\", \"PLZL\", \"ROSN\", \"RTKM\", \"SBER\", \"SNGS\", \"TATN\", \"TCSG\", \"VKCO\", \"VTBR\", \"YNDX\"\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ –ó–∞–≥—Ä—É–∑–∏–º {len(TICKERS)} —Ç–∏–∫–µ—Ä–æ–≤\")\n",
        "print(f\"–¢–∏–∫–µ—Ä—ã: {TICKERS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –†–∞—Å—á–µ—Ç –¥–ª—è –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ç–∏–∫–µ—Ä—ã\n",
        "results = {}\n",
        "horizons = [1, 5, 10]\n",
        "\n",
        "for ticker in TICKERS:\n",
        "    try:\n",
        "        print(f\"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {ticker}...\", end=\" \")\n",
        "        \n",
        "        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "        input_path = DATA_DIR / f\"{ticker}_ohlcv_returns.parquet\"\n",
        "        if not input_path.exists():\n",
        "            print(f\"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}\")\n",
        "            continue\n",
        "        \n",
        "        df = pd.read_parquet(input_path)\n",
        "        \n",
        "        # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
        "        df = create_all_targets(df, horizons=horizons)\n",
        "        \n",
        "        # 3. –ü–æ–¥—Å—á–µ—Ç —Ü–µ–ª–µ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤\n",
        "        target_cols = [col for col in df.columns if col.startswith(\"target_\") or col.startswith(\"quantile_\")]\n",
        "        \n",
        "        # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "        results[ticker] = df\n",
        "        print(f\"‚úÖ –ì–æ—Ç–æ–≤–æ ({len(df)} —Å—Ç—Ä–æ–∫, {len(target_cols)} —Ü–µ–ª–µ–≤—ã—Ö)\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {ticker}: {e}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results)} –∏–∑ {len(TICKERS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ü—Ä–∏–º–µ—Ä –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ SBER\n",
        "sample_ticker = \"SBER\"\n",
        "if sample_ticker in results:\n",
        "    df_sample = results[sample_ticker]\n",
        "    \n",
        "    # –¶–µ–ª–µ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã\n",
        "    target_cols = [col for col in df_sample.columns if col.startswith(\"target_\") or col.startswith(\"quantile_\")]\n",
        "    print(f\"–¶–µ–ª–µ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {target_cols}\")\n",
        "    \n",
        "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "    print(f\"\\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (5 –¥–Ω–µ–π) ===\")\n",
        "    print(df_sample[\"target_vol_5d\"].describe())\n",
        "    \n",
        "    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ spike flag\n",
        "    print(f\"\\n=== –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ spike flag ===\")\n",
        "    print(df_sample[\"target_spike\"].value_counts())\n",
        "    spike_rate = df_sample[\"target_spike\"].mean()\n",
        "    print(f\"–î–æ–ª—è –≤—Å–ø–ª–µ—Å–∫–æ–≤: {spike_rate:.2%}\")\n",
        "    \n",
        "    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ direction\n",
        "    print(f\"\\n=== –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ direction ===\")\n",
        "    print(df_sample[\"target_direction\"].value_counts())\n",
        "    growth_rate = df_sample[\"target_direction\"].mean()\n",
        "    print(f\"–î–æ–ª—è —Ä–æ—Å—Ç–∞: {growth_rate:.2%}\")\n",
        "    \n",
        "    # –ö–≤–∞–Ω—Ç–∏–ª–∏\n",
        "    print(f\"\\n=== –ö–≤–∞–Ω—Ç–∏–ª–∏ ===\")\n",
        "    print(df_sample[[\"quantile_16\", \"quantile_50\", \"quantile_84\"]].describe())\n",
        "    \n",
        "    # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\n",
        "    print(f\"\\n=== –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π ===\")\n",
        "    display_cols = [\"date\", \"close\", \"log_return\", \"target_vol_5d\", \"target_spike\", \"target_direction\"]\n",
        "    print(df_sample[display_cols].tail(10))\n",
        "else:\n",
        "    print(f\"–¢–∏–∫–µ—Ä {sample_ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "for ticker, df in results.items():\n",
        "    output_path = OUTPUT_DIR / f\"{ticker}_with_targets.parquet\"\n",
        "    df.to_parquet(output_path, index=False)\n",
        "    print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\")\n",
        "\n",
        "print(f\"\\nüéâ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {OUTPUT_DIR}\")\n",
        "\n",
        "# –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "if results:\n",
        "    sample_df = list(results.values())[0]\n",
        "    target_cols = [col for col in sample_df.columns if col.startswith(\"target_\") or col.startswith(\"quantile_\")]\n",
        "    print(f\"\\nüìä –ò—Ç–æ–≥–æ:\")\n",
        "    print(f\"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {len(results)}\")\n",
        "    print(f\"   –¶–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {len(target_cols)}\")\n",
        "    print(f\"   –í—Å–µ–≥–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {len(sample_df.columns)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
