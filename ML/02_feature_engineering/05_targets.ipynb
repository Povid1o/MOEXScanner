{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
        "\n",
        "- –¶–µ–ª–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏: realized volatility horizon, spike_flag, quantiles\n",
        "- –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è target'–æ–≤, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
        "\n",
        "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è ML-–∑–∞–¥–∞—á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–º–µ—â–µ–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§—É–Ω–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_realized_vol_target(returns, horizon=5):\n",
        "    \"\"\"\n",
        "    –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ\n",
        "    –°–¥–≤–∏–≥ –Ω–∞ –±—É–¥—É—â–µ–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "    \"\"\"\n",
        "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ 'horizon' –¥–Ω–µ–π\n",
        "    target = returns.rolling(window=horizon).std().shift(-horizon) * np.sqrt(252)\n",
        "    return target\n",
        "\n",
        "\n",
        "def create_spike_flag(returns, threshold=2.0, window=20):\n",
        "    \"\"\"\n",
        "    –ë–∏–Ω–∞—Ä–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è: –±—É–¥–µ—Ç –ª–∏ –≤—Å–ø–ª–µ—Å–∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "    1 = –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞, 0 = –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
        "    \"\"\"\n",
        "    # –†–∞—Å—á–µ—Ç z-score –Ω–∞ –±—É–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥\n",
        "    future_returns = returns.shift(-1)\n",
        "    ma = returns.rolling(window=window).mean()\n",
        "    std = returns.rolling(window=window).std()\n",
        "    z_score = np.abs((future_returns - ma) / std)\n",
        "    \n",
        "    spike = (z_score > threshold).astype(int)\n",
        "    return spike\n",
        "\n",
        "\n",
        "def create_quantile_targets(returns, horizon=5, quantiles=[0.16, 0.50, 0.84]):\n",
        "    \"\"\"\n",
        "    –ö–≤–∞–Ω—Ç–∏–ª–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –±—É–¥—É—â–∏—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π\n",
        "    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è quantile regression\n",
        "    \"\"\"\n",
        "    targets = {}\n",
        "    for q in quantiles:\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º –∫–≤–∞–Ω—Ç–∏–ª—å –Ω–∞ —Å–∫–æ–ª—å–∑—è—â–µ–º –æ–∫–Ω–µ –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "        target = returns.rolling(window=horizon).quantile(q).shift(-horizon)\n",
        "        targets[f'quantile_{int(q*100)}'] = target\n",
        "    \n",
        "    return pd.DataFrame(targets)\n",
        "\n",
        "\n",
        "def create_directional_target(returns, horizon=1):\n",
        "    \"\"\"\n",
        "    –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è: 1 = –≤–≤–µ—Ä—Ö, 0 = –≤–Ω–∏–∑\n",
        "    –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "    \"\"\"\n",
        "    future_return = returns.shift(-horizon)\n",
        "    direction = (future_return > 0).astype(int)\n",
        "    return direction\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "DATA_DIR = Path('data') / 'processed'\n",
        "ticker = 'SBER'\n",
        "df = pd.read_parquet(DATA_DIR / f\"{ticker}_ohlcv_returns.parquet\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
        "horizons = [1, 5, 10]\n",
        "\n",
        "for h in horizons:\n",
        "    df[f'target_vol_{h}d'] = create_realized_vol_target(df['log_return'], horizon=h)\n",
        "\n",
        "# –°–ø–∞–π–∫ —Ñ–ª–∞–≥\n",
        "df['target_spike'] = create_spike_flag(df['log_return'], threshold=2.0, window=20)\n",
        "\n",
        "# –ö–≤–∞–Ω—Ç–∏–ª–∏\n",
        "quantile_df = create_quantile_targets(df['log_return'], horizon=5, quantiles=[0.16, 0.50, 0.84])\n",
        "df = pd.concat([df, quantile_df], axis=1)\n",
        "\n",
        "# –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ\n",
        "df['target_direction'] = create_directional_target(df['log_return'], horizon=1)\n",
        "\n",
        "print(\"‚úÖ –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã\")\n",
        "print(f\"\\n–°—Ç–æ–ª–±—Ü—ã —Å —Ü–µ–ª–µ–≤—ã–º–∏:\")\n",
        "target_cols = [col for col in df.columns if col.startswith('target_') or col.startswith('quantile_')]\n",
        "print(target_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
        "print(\"\\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (5 –¥–Ω–µ–π) ===\")\n",
        "print(df['target_vol_5d'].describe())\n",
        "\n",
        "print(\"\\n=== –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ spike flag ===\")\n",
        "print(df['target_spike'].value_counts())\n",
        "print(f\"–î–æ–ª—è –≤—Å–ø–ª–µ—Å–∫–æ–≤: {df['target_spike'].mean():.2%}\")\n",
        "\n",
        "print(\"\\n=== –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ direction ===\")\n",
        "print(df['target_direction'].value_counts())\n",
        "print(f\"–î–æ–ª—è —Ä–æ—Å—Ç–∞: {df['target_direction'].mean():.2%}\")\n",
        "\n",
        "print(\"\\n=== –ö–≤–∞–Ω—Ç–∏–ª–∏ ===\")\n",
        "print(df[['quantile_16', 'quantile_50', 'quantile_84']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_DIR = Path('data') / 'features'\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "output_path = OUTPUT_DIR / f\"{ticker}_with_targets.parquet\"\n",
        "df.to_parquet(output_path, index=False)\n",
        "print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\")\n",
        "print(f\"\\nüìä –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
