{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è Global ML Model)\n",
        "\n",
        "**–†–ï–§–ê–ö–¢–û–†–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù** - –≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥—É–ª—å `features.trend_features`\n",
        "\n",
        "## –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:\n",
        "- ‚ùå **–£–î–ê–õ–ï–ù–´** –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è MA (sma_20, sma_50, ema_20...)\n",
        "- ‚úÖ **–î–û–ë–ê–í–õ–ï–ù–´** –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è: `dist_to_sma_*`, `dist_to_ema_*`\n",
        "\n",
        "## –§–æ—Ä–º—É–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏:\n",
        "```\n",
        "dist_to_sma_50 = (close / SMA_50) - 1\n",
        "```\n",
        "\n",
        "## –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
        "- `dist_to_sma_20/50/200` - —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ SMA –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö\n",
        "- `dist_to_ema_20/50` - —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ EMA –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö  \n",
        "- `sma_20_slope_norm`, `sma_50_slope_norm` - –Ω–∞–∫–ª–æ–Ω MA (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π)\n",
        "- `momentum_10/20` - log return –∑–∞ –ø–µ—Ä–∏–æ–¥\n",
        "- `rsi_14` - RSI (—É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω 0-100)\n",
        "- `trend_signal`, `trend_strength` - —Å–∏–≥–Ω–∞–ª —Ç—Ä–µ–Ω–¥–∞\n",
        "\n",
        "**–û—Å–Ω–æ–≤–Ω–æ–π pipeline**: —Å–º. `06_feature_aggregator.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ML –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "from features.trend_features import (\n",
        "    build_trend_features,\n",
        "    dist_to_ma,\n",
        "    rsi,\n",
        "    momentum_normalized,\n",
        "    trend_signal,\n",
        "    trend_strength,\n",
        "    TREND_FEATURE_COLUMNS\n",
        ")\n",
        "\n",
        "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π\n",
        "ML_ROOT = Path.cwd().parent\n",
        "DATA_DIR = ML_ROOT / \"data\" / \"processed\"\n",
        "\n",
        "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –º–æ–¥—É–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
        "print(f\"üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: {DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§—É–Ω–∫—Ü–∏–∏ —Ä–∞—Å—á–µ—Ç–∞ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§—É–Ω–∫—Ü–∏–∏ —Ç–µ–ø–µ—Ä—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ –º–æ–¥—É–ª—è features.trend_features\n",
        "# \n",
        "# –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:\n",
        "# - dist_to_ma(prices, ma_values) -> –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ MA\n",
        "# - rsi(prices, window=14) -> RSI (0-100)\n",
        "# - momentum_normalized(prices, window) -> log return –∑–∞ –ø–µ—Ä–∏–æ–¥\n",
        "# - trend_signal(ma_short, ma_long, threshold) -> —Å–∏–≥–Ω–∞–ª —Ç—Ä–µ–Ω–¥–∞ (-1, 0, 1)\n",
        "# - trend_strength(ma_short, ma_long) -> —Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)\n",
        "# - build_trend_features(df) -> –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–∞–∑—É\n",
        "#\n",
        "# –í–ê–ñ–ù–û: –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ï –∑–Ω–∞—á–µ–Ω–∏—è!\n",
        "# –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ MA –ù–ï —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –≤ –∏—Ç–æ–≥–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç.\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ –º–æ–¥—É–ª—è\")\n",
        "print(f\"üìã –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {TREND_FEATURE_COLUMNS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "ticker = 'SBER'\n",
        "df = pd.read_parquet(DATA_DIR / f\"{ticker}_ohlcv_returns.parquet\")\n",
        "print(f\"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {ticker}\")\n",
        "\n",
        "# –†–∞—Å—á–µ—Ç –í–°–ï–• –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–¥–Ω–∏–º –≤—ã–∑–æ–≤–æ–º\n",
        "trend_features = build_trend_features(df)\n",
        "\n",
        "print(f\"‚úÖ –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã: {len(trend_features.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "print(f\"\\nüìã –ü—Ä–∏–∑–Ω–∞–∫–∏:\")\n",
        "for col in trend_features.columns:\n",
        "    print(f\"   ‚Ä¢ {col}\")\n",
        "\n",
        "print(f\"\\nüìä –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (–ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ï):\")\n",
        "display(trend_features.tail(10))\n",
        "\n",
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: —Å—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥ vs –Ω–æ–≤—ã–π\n",
        "print(f\"\\n‚ö†Ô∏è –í–ê–ñ–ù–û: –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–∏—á–∏—è:\")\n",
        "print(f\"   –†–ê–ù–¨–®–ï: sma_50 = 285.12 (–∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Ü–µ–Ω–∞)\")\n",
        "print(f\"   –°–ï–ô–ß–ê–°: dist_to_sma_50 = 0.023 (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ = +2.3%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "# –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –î–ª—è –ø–æ–ª–Ω–æ–≥–æ pipeline –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ 06_feature_aggregator.ipynb\n",
        "# –≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
        "\n",
        "OUTPUT_DIR = ML_ROOT / \"data\" / \"features\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¢–û–õ–¨–ö–û –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–±–µ–∑ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö MA!)\n",
        "output_path = OUTPUT_DIR / f\"{ticker}_trend_features_normalized.parquet\"\n",
        "trend_features.to_parquet(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\")\n",
        "print(f\"   –°—Ç—Ä–æ–∫: {len(trend_features)}\")\n",
        "print(f\"   –°—Ç–æ–ª–±—Ü–æ–≤: {len(trend_features.columns)}\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –Ω–µ—Ç –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö MA\n",
        "forbidden = ['sma_20', 'sma_50', 'sma_200', 'ema_20', 'ema_50']\n",
        "found = [col for col in trend_features.columns if col in forbidden]\n",
        "if found:\n",
        "    print(f\"\\n‚ùå –û–®–ò–ë–ö–ê: –ù–∞–π–¥–µ–Ω—ã –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {found}\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–π–¥–µ–Ω–∞: –Ω–µ—Ç –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö MA –∑–Ω–∞—á–µ–Ω–∏–π\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
