{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Рыночные признаки\n",
        "\n",
        "- Бета коэффициент к индексу IMOEX\n",
        "- Корреляция за 60 дней\n",
        "- Волатильность индекса\n",
        "\n",
        "Оценивается связь тикера с общерыночными факторами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Библиотеки загружены\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Библиотеки загружены\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Текущая директория: e:\\Python\\VolatilityChecker\\MOEXScanner\\ML\\02_feature_engineering\n",
            "Путь к данным: e:\\Python\\VolatilityChecker\\MOEXScanner\\ML\\data\\processed\n",
            "Директория найдена!\n",
            "Всего тикеров: 30\n"
          ]
        }
      ],
      "source": [
        "# Получаем текущую рабочую директорию\n",
        "current_dir = Path.cwd()\n",
        "print(f\"Текущая директория: {current_dir}\")\n",
        "\n",
        "# Строим путь к данным\n",
        "DATA_DIR = current_dir.parent.parent / 'ML' / 'data' / 'processed'\n",
        "print(f\"Путь к данным: {DATA_DIR}\")\n",
        "\n",
        "if DATA_DIR.exists():\n",
        "    print(\"Директория найдена!\")\n",
        "else:\n",
        "    print(\"Директория не найдена, проверьте путь\")\n",
        "\n",
        "# Список всех тикеров\n",
        "TICKERS = [\n",
        "    'AFKS', 'AFLT', 'ALRS', 'BELU', 'BSPB', 'CHMF', 'FIVE',\n",
        "    'GAZP', 'GMKN', 'HYDR', 'IRAO', 'LENT', 'LKOH', 'MAGN',\n",
        "    'MGNT', 'MTSS', 'NLMK', 'NVTK', 'OZON', 'PIKK', 'PLZL',\n",
        "    'ROSN', 'RTKM', 'SBER', 'SNGS', 'TATN', 'TCSG', 'VKCO',\n",
        "    'VTBR', 'YNDX'\n",
        "]\n",
        "print(f\"Всего тикеров: {len(TICKERS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка и диагностика индекса IMOEX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMOEX загружен: 1253 записей\n",
            "Период: 2020-10-13 00:00:00 - 2025-10-10 00:00:00\n",
            "\n",
            "SBER загружен: 1301 записей\n",
            "Период: 2020-10-13 23:59:59 - 2025-10-11 15:00:27\n",
            "\n",
            "--- ДИАГНОСТИКА ---\n",
            "Уникальных дат SBER: 1301\n",
            "Уникальных дат IMOEX: 1253\n",
            "Общих дат: 1252\n",
            "Дат только в SBER: 49\n",
            "Дат только в IMOEX: 1\n",
            "\n",
            "Последние 10 дат SBER без данных IMOEX:\n",
            "  2025-08-31\n",
            "  2025-09-06\n",
            "  2025-09-07\n",
            "  2025-09-13\n",
            "  2025-09-14\n",
            "  2025-09-27\n",
            "  2025-09-28\n",
            "  2025-10-04\n",
            "  2025-10-05\n",
            "  2025-10-11\n"
          ]
        }
      ],
      "source": [
        "# Загрузка индекса IMOEX\n",
        "index_df = pd.read_parquet(DATA_DIR / 'IMOEX_ohlcv_returns.parquet')\n",
        "print(f\"IMOEX загружен: {len(index_df)} записей\")\n",
        "print(f\"Период: {index_df['date'].min()} - {index_df['date'].max()}\")\n",
        "\n",
        "# Нормализуем дату\n",
        "index_df['date_only'] = pd.to_datetime(index_df['date']).dt.normalize()\n",
        "\n",
        "# Загружаем SBER для сравнения\n",
        "sber_df = pd.read_parquet(DATA_DIR / 'SBER_ohlcv_returns.parquet')\n",
        "print(f\"\\nSBER загружен: {len(sber_df)} записей\")\n",
        "print(f\"Период: {sber_df['date'].min()} - {sber_df['date'].max()}\")\n",
        "\n",
        "# Диагностика: сравним количество торговых дней\n",
        "sber_df['date_only'] = pd.to_datetime(sber_df['date']).dt.normalize()\n",
        "\n",
        "sber_dates = set(sber_df['date_only'])\n",
        "imoex_dates = set(index_df['date_only'])\n",
        "\n",
        "print(f\"\\n--- ДИАГНОСТИКА ---\")\n",
        "print(f\"Уникальных дат SBER: {len(sber_dates)}\")\n",
        "print(f\"Уникальных дат IMOEX: {len(imoex_dates)}\")\n",
        "print(f\"Общих дат: {len(sber_dates & imoex_dates)}\")\n",
        "print(f\"Дат только в SBER: {len(sber_dates - imoex_dates)}\")\n",
        "print(f\"Дат только в IMOEX: {len(imoex_dates - sber_dates)}\")\n",
        "\n",
        "# Показать последние даты без совпадений\n",
        "missing_in_imoex = sorted(sber_dates - imoex_dates)\n",
        "if missing_in_imoex:\n",
        "    print(f\"\\nПоследние 10 дат SBER без данных IMOEX:\")\n",
        "    for d in missing_in_imoex[-10:]:\n",
        "        print(f\"  {d.date()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Функции расчета рыночных признаков\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Функции рыночных признаков загружены\n"
          ]
        }
      ],
      "source": [
        "def calculate_beta(stock_returns, market_returns, window=60, min_periods=None):\n",
        "    \"\"\"Расчет бета коэффициента к рынку (индексу)\n",
        "    \n",
        "    min_periods: минимальное количество непропущенных значений в окне\n",
        "    \"\"\"\n",
        "    if min_periods is None:\n",
        "        min_periods = int(window * 0.7)  # Требуем минимум 70% данных в окне\n",
        "    \n",
        "    beta_list = []\n",
        "    \n",
        "    for i in range(len(stock_returns)):\n",
        "        if i < window:\n",
        "            beta_list.append(np.nan)\n",
        "            continue\n",
        "        \n",
        "        stock_window = stock_returns.iloc[i-window:i]\n",
        "        market_window = market_returns.iloc[i-window:i]\n",
        "        \n",
        "        # Убираем NaN для расчёта\n",
        "        valid_mask = ~(stock_window.isna() | market_window.isna())\n",
        "        valid_count = valid_mask.sum()\n",
        "        \n",
        "        if valid_count < min_periods:\n",
        "            beta_list.append(np.nan)\n",
        "            continue\n",
        "        \n",
        "        stock_valid = stock_window[valid_mask]\n",
        "        market_valid = market_window[valid_mask]\n",
        "        \n",
        "        covariance = stock_valid.cov(market_valid)\n",
        "        market_variance = market_valid.var()\n",
        "        \n",
        "        beta = covariance / market_variance if market_variance > 0 else np.nan\n",
        "        beta_list.append(beta)\n",
        "    \n",
        "    return pd.Series(beta_list, index=stock_returns.index)\n",
        "\n",
        "\n",
        "def calculate_correlation(stock_returns, market_returns, window=60, min_periods=None):\n",
        "    \"\"\"Скользящая корреляция с индексом (устойчивая к NaN)\"\"\"\n",
        "    if min_periods is None:\n",
        "        min_periods = int(window * 0.7)\n",
        "    \n",
        "    corr_list = []\n",
        "    \n",
        "    for i in range(len(stock_returns)):\n",
        "        if i < window:\n",
        "            corr_list.append(np.nan)\n",
        "            continue\n",
        "        \n",
        "        stock_window = stock_returns.iloc[i-window:i]\n",
        "        market_window = market_returns.iloc[i-window:i]\n",
        "        \n",
        "        # Убираем NaN\n",
        "        valid_mask = ~(stock_window.isna() | market_window.isna())\n",
        "        valid_count = valid_mask.sum()\n",
        "        \n",
        "        if valid_count < min_periods:\n",
        "            corr_list.append(np.nan)\n",
        "            continue\n",
        "        \n",
        "        corr = stock_window[valid_mask].corr(market_window[valid_mask])\n",
        "        corr_list.append(corr)\n",
        "    \n",
        "    return pd.Series(corr_list, index=stock_returns.index)\n",
        "\n",
        "\n",
        "def market_volatility(market_returns, window=30, min_periods=None):\n",
        "    \"\"\"Волатильность рынка (устойчивая к NaN)\"\"\"\n",
        "    if min_periods is None:\n",
        "        min_periods = int(window * 0.7)\n",
        "    return market_returns.rolling(window=window, min_periods=min_periods).std() * np.sqrt(252)\n",
        "\n",
        "\n",
        "def calculate_market_features(df, index_df, windows=[30, 60]):\n",
        "    \"\"\"Расчет всех рыночных признаков для тикера\"\"\"\n",
        "    df = df.copy()\n",
        "    df['date_only'] = pd.to_datetime(df['date']).dt.normalize()\n",
        "    \n",
        "    # Объединяем по нормализованной дате\n",
        "    merged = pd.merge(\n",
        "        df, \n",
        "        index_df[['date_only', 'log_return']], \n",
        "        on='date_only', \n",
        "        how='left', \n",
        "        suffixes=('', '_index')\n",
        "    )\n",
        "    merged['index_return'] = merged['log_return_index']\n",
        "    \n",
        "    # Расчет признаков для разных окон\n",
        "    for window in windows:\n",
        "        merged[f'beta_{window}'] = calculate_beta(\n",
        "            merged['log_return'], merged['index_return'], window=window\n",
        "        )\n",
        "        merged[f'correlation_{window}'] = calculate_correlation(\n",
        "            merged['log_return'], merged['index_return'], window=window\n",
        "        )\n",
        "        merged[f'index_vol_{window}'] = market_volatility(\n",
        "            merged['index_return'], window=window\n",
        "        )\n",
        "    \n",
        "    # Удаляем вспомогательные колонки\n",
        "    merged = merged.drop(columns=['date_only', 'log_return_index'], errors='ignore')\n",
        "    \n",
        "    return merged\n",
        "\n",
        "print(\"Функции рыночных признаков загружены\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Расчет для всех тикеров\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AFKS: 1301 записей, 1252 совпадений с индексом\n",
            "AFLT: 1301 записей, 1252 совпадений с индексом\n",
            "ALRS: 1301 записей, 1252 совпадений с индексом\n",
            "BELU: 1289 записей, 1246 совпадений с индексом\n",
            "BSPB: 1295 записей, 1250 совпадений с индексом\n",
            "CHMF: 1301 записей, 1252 совпадений с индексом\n",
            "FIVE: 242 записей, 193 совпадений с индексом\n",
            "GAZP: 1301 записей, 1252 совпадений с индексом\n",
            "GMKN: 1297 записей, 1248 совпадений с индексом\n",
            "HYDR: 1301 записей, 1252 совпадений с индексом\n",
            "IRAO: 1299 записей, 1252 совпадений с индексом\n",
            "LENT: 990 записей, 951 совпадений с индексом\n",
            "LKOH: 1301 записей, 1252 совпадений с индексом\n",
            "MAGN: 1301 записей, 1252 совпадений с индексом\n",
            "MGNT: 1301 записей, 1252 совпадений с индексом\n",
            "MTSS: 1300 записей, 1252 совпадений с индексом\n",
            "NLMK: 1301 записей, 1252 совпадений с индексом\n",
            "NVTK: 1297 записей, 1252 совпадений с индексом\n",
            "OZON: 1205 записей, 1205 совпадений с индексом\n",
            "PIKK: 1301 записей, 1252 совпадений с индексом\n",
            "PLZL: 1297 записей, 1249 совпадений с индексом\n",
            "ROSN: 1301 записей, 1252 совпадений с индексом\n",
            "RTKM: 1301 записей, 1252 совпадений с индексом\n",
            "SBER: 1301 записей, 1252 совпадений с индексом\n",
            "SNGS: 1301 записей, 1252 совпадений с индексом\n",
            "TATN: 1299 записей, 1252 совпадений с индексом\n",
            "TCSG: 1009 записей, 1009 совпадений с индексом\n",
            "VKCO: 976 записей, 927 совпадений с индексом\n",
            "VTBR: 1297 записей, 1248 совпадений с индексом\n",
            "YNDX: 356 записей, 311 совпадений с индексом\n",
            "\n",
            "Обработано: 30 из 30\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "windows = [30, 60]\n",
        "\n",
        "for ticker in TICKERS:\n",
        "    try:\n",
        "        df = pd.read_parquet(DATA_DIR / f\"{ticker}_ohlcv_returns.parquet\")\n",
        "        df_features = calculate_market_features(df, index_df, windows=windows)\n",
        "        \n",
        "        valid_rows = df_features['index_return'].notna().sum()\n",
        "        results[ticker] = df_features\n",
        "        print(f\"{ticker}: {len(df_features)} записей, {valid_rows} совпадений с индексом\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"{ticker}: ОШИБКА - {e}\")\n",
        "\n",
        "print(f\"\\nОбработано: {len(results)} из {len(TICKERS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример и диагностика\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Столбцы: ['date', 'open', 'high', 'low', 'close', 'volume', 'value', 'log_return', 'index_return', 'beta_30', 'correlation_30', 'index_vol_30', 'beta_60', 'correlation_60', 'index_vol_60']\n",
            "\n",
            "Пример данных из СЕРЕДИНЫ датасета (где индекс точно есть):\n",
            "                   date   close  log_return  index_return   beta_60  \\\n",
            "650 2023-06-05 23:59:59  237.12   -0.028397     -0.009362  1.309478   \n",
            "651 2023-06-06 23:59:59  240.91    0.015857     -0.004796  1.340594   \n",
            "652 2023-06-07 23:59:59  241.25    0.001410      0.005000  1.323537   \n",
            "653 2023-06-08 23:59:59  241.77    0.002153      0.005551  1.320676   \n",
            "654 2023-06-09 23:59:59  240.40   -0.005683     -0.000609  1.310085   \n",
            "655 2023-06-13 23:59:59  244.33    0.016216      0.018020  1.348618   \n",
            "656 2023-06-14 23:59:59  244.60    0.001104      0.002861  1.326412   \n",
            "657 2023-06-15 23:59:59  245.18    0.002368      0.012574  1.028927   \n",
            "658 2023-06-16 23:59:59  243.87   -0.005357      0.000221  0.885056   \n",
            "659 2023-06-19 23:59:59  242.28   -0.006541      0.005086  0.886917   \n",
            "\n",
            "     correlation_60  \n",
            "650        0.642199  \n",
            "651        0.651405  \n",
            "652        0.640944  \n",
            "653        0.638544  \n",
            "654        0.634392  \n",
            "655        0.639485  \n",
            "656        0.638825  \n",
            "657        0.582347  \n",
            "658        0.500512  \n",
            "659        0.500787  \n",
            "\n",
            "Последние 10 записей:\n",
            "                    date   close  log_return  index_return   beta_60  \\\n",
            "1291 2025-10-02 23:59:59  285.22   -0.004129     -0.005751  0.398895   \n",
            "1292 2025-10-03 23:59:59  282.91   -0.008132     -0.010511  0.378735   \n",
            "1293 2025-10-04 23:59:57  280.40   -0.008912           NaN  0.381488   \n",
            "1294 2025-10-05 23:59:57  281.99    0.005654           NaN  0.379558   \n",
            "1295 2025-10-06 23:59:55  290.56    0.029938      0.016734  0.376596   \n",
            "1296 2025-10-07 23:59:54  293.89    0.011395      0.007561  0.445143   \n",
            "1297 2025-10-08 23:59:51  281.90   -0.041653     -0.040567  0.441847   \n",
            "1298 2025-10-09 23:59:55  289.37    0.026154      0.029174  0.565405   \n",
            "1299 2025-10-10 23:59:55  285.12   -0.014796     -0.019060  0.613613   \n",
            "1300 2025-10-11 15:00:27  284.44   -0.002388           NaN  0.700108   \n",
            "\n",
            "      correlation_60  \n",
            "1291        0.533838  \n",
            "1292        0.515005  \n",
            "1293        0.516155  \n",
            "1294        0.510788  \n",
            "1295        0.509939  \n",
            "1296        0.542968  \n",
            "1297        0.529978  \n",
            "1298        0.642642  \n",
            "1299        0.699890  \n",
            "1300        0.726723  \n",
            "\n",
            "--- СТАТИСТИКА ---\n",
            "Всего записей: 1301\n",
            "index_return: 1252 значений, 49 NaN\n",
            "\n",
            "Средние значения (где есть данные):\n",
            "  beta_60: 0.963\n",
            "  correlation_60: 0.675\n"
          ]
        }
      ],
      "source": [
        "sample_ticker = 'SBER'\n",
        "if sample_ticker in results:\n",
        "    df_sample = results[sample_ticker]\n",
        "    \n",
        "    print(f\"Столбцы: {df_sample.columns.tolist()}\")\n",
        "    \n",
        "    # Показать данные из середины (где должны быть полные данные)\n",
        "    print(f\"\\nПример данных из СЕРЕДИНЫ датасета (где индекс точно есть):\")\n",
        "    mid_idx = len(df_sample) // 2\n",
        "    print(df_sample[['date', 'close', 'log_return', 'index_return', 'beta_60', 'correlation_60']].iloc[mid_idx:mid_idx+10])\n",
        "    \n",
        "    # Показать последние данные\n",
        "    print(f\"\\nПоследние 10 записей:\")\n",
        "    print(df_sample[['date', 'close', 'log_return', 'index_return', 'beta_60', 'correlation_60']].tail(10))\n",
        "    \n",
        "    # Статистика\n",
        "    print(f\"\\n--- СТАТИСТИКА ---\")\n",
        "    print(f\"Всего записей: {len(df_sample)}\")\n",
        "    print(f\"index_return: {df_sample['index_return'].notna().sum()} значений, {df_sample['index_return'].isna().sum()} NaN\")\n",
        "    \n",
        "    # Средние значения beta и correlation (без NaN)\n",
        "    print(f\"\\nСредние значения (где есть данные):\")\n",
        "    print(f\"  beta_60: {df_sample['beta_60'].mean():.3f}\")\n",
        "    print(f\"  correlation_60: {df_sample['correlation_60'].mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сохранение результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_DIR = Path('data') / 'features'\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for ticker, df in results.items():\n",
        "    output_path = OUTPUT_DIR / f\"{ticker}_market_features.parquet\"\n",
        "    df.to_parquet(output_path, index=False)\n",
        "    print(f\"Сохранено: {output_path}\")\n",
        "\n",
        "print(f\"\\nВсе данные сохранены в {OUTPUT_DIR}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
