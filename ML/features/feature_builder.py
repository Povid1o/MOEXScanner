"""
–ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä Feature Engineering Pipeline –¥–ª—è Global ML Model.

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –º–æ–¥—É–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
1. –†–∞—Å—á–µ—Ç –í–°–ï–• –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ ML –∏ Backtest –≤—ã—Ö–æ–¥–Ω—ã–µ –Ω–∞–±–æ—Ä—ã
3. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–∞ (ticker_id, sector_id)
4. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–ö–†–ò–¢–ò–ß–ù–û: ML –≤—ã—Ö–æ–¥ –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Ü–µ–Ω/–æ–±—ä–µ–º–∞!
"""

import numpy as np
import pandas as pd
from pathlib import Path
from typing import Tuple, List, Optional, Dict
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir.parent))

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
from features.volume_features import build_volume_features, VOLUME_FEATURE_COLUMNS
from features.trend_features import build_trend_features, TREND_FEATURE_COLUMNS
from features.calendar_features import build_calendar_features, CALENDAR_FEATURE_COLUMNS

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
try:
    from config import get_ticker_metadata, encode_metadata_features
except ImportError:
    # Fallback –µ—Å–ª–∏ config –Ω–µ –Ω–∞–π–¥–µ–Ω
    def get_ticker_metadata(ticker): return None
    def encode_metadata_features(ticker): return {}


# === –ó–ê–ü–†–ï–©–ï–ù–ù–´–ï –°–¢–û–õ–ë–¶–´ –î–õ–Ø ML –í–´–•–û–î–ê ===
FORBIDDEN_ML_COLUMNS = [
    'open', 'high', 'low', 'close', 'volume', 'value',
    'sma_20', 'sma_50', 'sma_200', 'ema_20', 'ema_50',  # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ MA
    'vp_poc', 'vp_va_high', 'vp_va_low',  # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ VP
    'volume_ma', 'begin', 'end'
]


def validate_ml_output(df: pd.DataFrame, ticker: str) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è ML –≤—ã—Ö–æ–¥–∞: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤.
    
    Args:
        df: DataFrame —Å ML –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        ticker: –¢–∏–∫–µ—Ä –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        True –µ—Å–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞
        
    Raises:
        ValueError –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
    """
    found_forbidden = []
    for col in df.columns:
        if col.lower() in [f.lower() for f in FORBIDDEN_ML_COLUMNS]:
            found_forbidden.append(col)
                
    if found_forbidden:
        raise ValueError(
            f"[{ticker}] –û–®–ò–ë–ö–ê –í–ê–õ–ò–î–ê–¶–ò–ò: ML –≤—ã—Ö–æ–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {found_forbidden}\n"
            f"ML –¥–∞–Ω–Ω—ã–µ –Ω–µ –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ü–µ–Ω/–æ–±—ä–µ–º–∞!"
        )
    
    return True


def handle_infinities(df: pd.DataFrame) -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: –∑–∞–º–µ–Ω–∞ –Ω–∞ NaN.
    
    Args:
        df: DataFrame —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º–∏ inf –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        
    Returns:
        DataFrame –±–µ–∑ inf –∑–Ω–∞—á–µ–Ω–∏–π
    """
    return df.replace([np.inf, -np.inf], np.nan)


def build_all_features(
    df: pd.DataFrame,
    ticker: str,
    include_volatility: bool = True
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Å—Ç—Ä–æ–∏—Ç –í–°–ï –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –Ω–∞ ML/Backtest –≤—ã—Ö–æ–¥—ã.
    
    Args:
        df: DataFrame —Å OHLCV –∏ log_return
        ticker: –¢–∏–∫–µ—Ä –∞–∫—Ü–∏–∏
        include_volatility: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ df
        
    Returns:
        Tuple[ml_features, backtest_data]:
        - ml_features: –¢–û–õ–¨–ö–û –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ML
        - backtest_data: –°—ã—Ä—ã–µ OHLCV –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞
    """
    # –ö–æ–ø–∏—Ä—É–µ–º –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    df = df.copy()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    required_cols = ['open', 'high', 'low', 'close', 'volume']
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {missing}")
    
    print(f"  üìä –†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {ticker}...")
    
    # === 1. –û–ë–™–ï–ú–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ) ===
    print(f"    ‚Ä¢ –û–±—ä–µ–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏...")
    volume_features = build_volume_features(df)
    
    # === 2. –¢–†–ï–ù–î–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ) ===
    print(f"    ‚Ä¢ –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏...")
    trend_features = build_trend_features(df)
    
    # === 3. –ö–ê–õ–ï–ù–î–ê–†–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò + GAP ===
    print(f"    ‚Ä¢ –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ Gap...")
    calendar_features = build_calendar_features(df)
    
    # === 4. –°–û–ë–ò–†–ê–ï–ú ML FEATURES ===
    ml_features = pd.DataFrame(index=df.index)
    
    # –î–∞—Ç–∞ (–¥–ª—è join –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏)
    if 'date' in df.columns:
        ml_features['date'] = df['date']
    
    # Log return (–æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–∑–Ω–∞–∫)
    if 'log_return' in df.columns:
        ml_features['log_return'] = df['log_return']
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö)
    if include_volatility:
        vol_cols = [col for col in df.columns if 'vol_' in col.lower() or 'volatility' in col.lower()]
        for col in vol_cols:
            if col not in FORBIDDEN_ML_COLUMNS:
                ml_features[col] = df[col]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    ml_features = pd.concat([
        ml_features,
        volume_features,
        trend_features,
        calendar_features
    ], axis=1)
    
    # === 5. –î–û–ë–ê–í–õ–Ø–ï–ú –ú–ï–¢–ê–î–ê–ù–ù–´–ï –¢–ò–ö–ï–†–ê ===
    ml_features['ticker_id'] = ticker
    
    # Sector ID –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    meta = get_ticker_metadata(ticker)
    ml_features['sector_id'] = meta.get('sector', 'Unknown') if meta else 'Unknown'
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
    meta_features = encode_metadata_features(ticker)
    for key, value in meta_features.items():
        ml_features[key] = value
    
    # === 6. –û–ß–ò–°–¢–ö–ê ML FEATURES ===
    ml_features = handle_infinities(ml_features)
    
    # === 7. –í–ê–õ–ò–î–ê–¶–ò–Ø ===
    validate_ml_output(ml_features, ticker)
    
    # === 8. BACKTEST DATA (—Å—ã—Ä—ã–µ —Ü–µ–Ω—ã) ===
    backtest_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
    if 'date' not in df.columns and df.index.name == 'date':
        df = df.reset_index()
    
    backtest_cols_present = [col for col in backtest_columns if col in df.columns]
    backtest_data = df[backtest_cols_present].copy()
    
    print(f"    ‚úÖ –ì–æ—Ç–æ–≤–æ: {len(ml_features.columns)} ML –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, {len(backtest_data.columns)} Backtest —Å—Ç–æ–ª–±—Ü–æ–≤")
    
    return ml_features, backtest_data


def process_single_ticker(
    ticker: str,
    data_dir: Path,
    output_ml_dir: Path,
    output_backtest_dir: Path,
    input_suffix: str = "_ohlcv_returns.parquet"
) -> bool:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ç–∏–∫–µ—Ä: –∑–∞–≥—Ä—É–∂–∞–µ—Ç, —Å—á–∏—Ç–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç.
    
    Args:
        ticker: –¢–∏–∫–µ—Ä –∞–∫—Ü–∏–∏
        data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        output_ml_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è ML –≤—ã—Ö–æ–¥–∞
        output_backtest_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è Backtest –≤—ã—Ö–æ–¥–∞
        input_suffix: –°—É—Ñ—Ñ–∏–∫—Å –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        
    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
    """
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞
        input_path = data_dir / f"{ticker}{input_suffix}"
        df = pd.read_parquet(input_path)
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        ml_features, backtest_data = build_all_features(df, ticker)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ML features
        ml_path = output_ml_dir / f"{ticker}_ml_features.parquet"
        ml_features.to_parquet(ml_path, index=False)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Backtest data
        backtest_path = output_backtest_dir / f"{ticker}_price_data.parquet"
        backtest_data.to_parquet(backtest_path, index=False)
        
        print(f"  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {ml_path.name}, {backtest_path.name}")
        return True
        
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {ticker}: {e}")
        return False


def process_all_tickers(
    data_dir: Path,
    output_ml_dir: Path,
    output_backtest_dir: Path,
    tickers: Optional[List[str]] = None
) -> Tuple[int, List[str]]:
    """
    Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤.
    
    Args:
        data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        output_ml_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è ML –≤—ã—Ö–æ–¥–∞
        output_backtest_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è Backtest –≤—ã—Ö–æ–¥–∞
        tickers: –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ (–µ—Å–ª–∏ None - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã)
        
    Returns:
        Tuple[—É—Å–ø–µ—à–Ω–æ_–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, —Å–ø–∏—Å–æ–∫_–æ—à–∏–±–æ–∫]
    """
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    output_ml_dir.mkdir(parents=True, exist_ok=True)
    output_backtest_dir.mkdir(parents=True, exist_ok=True)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤
    if tickers is None:
        available_files = list(data_dir.glob("*_ohlcv_returns.parquet"))
        tickers = [f.stem.replace('_ohlcv_returns', '') for f in available_files]
    
    print(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(tickers)} —Ç–∏–∫–µ—Ä–æ–≤...")
    print(f"   –¢–∏–∫–µ—Ä—ã: {tickers}\n")
    
    processed = 0
    errors = []
    
    for ticker in tickers:
        print(f"üîÑ {ticker}...")
        success = process_single_ticker(
            ticker, data_dir, output_ml_dir, output_backtest_dir
        )
        if success:
            processed += 1
        else:
            errors.append(ticker)
    
    print(f"\n{'='*50}")
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ: {processed}/{len(tickers)}")
    if errors:
        print(f"‚ùå –û—à–∏–±–∫–∏: {errors}")
    
    return processed, errors


def get_ml_feature_columns() -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –í–°–ï–• ML –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏).
    """
    return (
        ['date', 'log_return'] +
        VOLUME_FEATURE_COLUMNS +
        TREND_FEATURE_COLUMNS +
        CALENDAR_FEATURE_COLUMNS +
        ['ticker_id', 'sector_id', 'sector_encoded', 'liquidity_rank', 'is_blue_chip', 'lot_size_log']
    )


# === –≠–ö–°–ü–û–†–¢ ===
__all__ = [
    'build_all_features',
    'process_single_ticker', 
    'process_all_tickers',
    'get_ml_feature_columns',
    'validate_ml_output',
    'FORBIDDEN_ML_COLUMNS'
]


if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
    from pathlib import Path
    
    ML_ROOT = Path(__file__).parent.parent
    DATA_DIR = ML_ROOT / "data" / "processed"
    OUTPUT_ML_DIR = ML_ROOT / "data" / "processed_ml"
    OUTPUT_BACKTEST_DIR = ML_ROOT / "data" / "backtest"
    
    print("üöÄ Feature Engineering Pipeline")
    print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {DATA_DIR}")
    print(f"   ML –≤—ã—Ö–æ–¥: {OUTPUT_ML_DIR}")
    print(f"   Backtest –≤—ã—Ö–æ–¥: {OUTPUT_BACKTEST_DIR}\n")
    
    process_all_tickers(DATA_DIR, OUTPUT_ML_DIR, OUTPUT_BACKTEST_DIR)

