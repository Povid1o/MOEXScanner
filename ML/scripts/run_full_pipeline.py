"""
üöÄ –ü–æ–ª–Ω—ã–π Production Pipeline –¥–ª—è MOEX Volatility Scanner

–ó–∞–ø—É—Å–∫:
    python scripts/run_full_pipeline.py [--preset PRESET] [--skip-features] [--skip-training] [--ticker SBER]

–≠—Ç–∞–ø—ã:
    1. Feature Engineering (D1 + H1 –ø—Ä–∏–∑–Ω–∞–∫–∏)
    2. Model Training (LightGBM Quantile) - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç config/training_config.py
    3. Inference + –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è –≤: config/training_config.py

–ê–≤—Ç–æ—Ä: ML Pipeline v2.0
"""

import argparse
import sys
import time
import re
from pathlib import Path
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
ML_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ML_ROOT))
sys.path.insert(0, str(ML_ROOT / "03_models"))
sys.path.insert(0, str(ML_ROOT / "config"))


def print_header(title: str):
    """–ü–µ—á–∞—Ç–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü–∏–∏."""
    print("\n" + "=" * 70)
    print(f"üî∑ {title}")
    print("=" * 70 + "\n")


def print_step(step: int, total: int, description: str):
    """–ü–µ—á–∞—Ç–∞–µ—Ç –Ω–æ–º–µ—Ä —à–∞–≥–∞."""
    print(f"\n[{step}/{total}] {description}")
    print("-" * 50)


def run_feature_engineering(include_intraday: bool = True):
    """
    –≠—Ç–∞–ø 1: Feature Engineering Pipeline.
    
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç D1 –¥–∞–Ω–Ω—ã–µ, —Å—á–∏—Ç–∞–µ—Ç –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤–∫–ª—é—á–∞—è H1 intraday),
    —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ processed_ml/.
    """
    print_header("–≠–¢–ê–ü 1: FEATURE ENGINEERING")
    
    from features.feature_builder import process_all_tickers
    
    start_time = time.time()
    
    processed, errors = process_all_tickers(
        data_dir=ML_ROOT / "data" / "processed",
        output_ml_dir=ML_ROOT / "data" / "processed_ml",
        output_backtest_dir=ML_ROOT / "data" / "backtest",
        include_intraday=include_intraday
    )
    
    elapsed = time.time() - start_time
    
    print(f"\n‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.1f} —Å–µ–∫")
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {processed}")
    
    if errors:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∏: {errors}")
    
    return processed > 0


def run_model_training():
    """
    –≠—Ç–∞–ø 2: Model Training Pipeline.
    
    –û–±—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å LightGBM.
    """
    print_header("–≠–¢–ê–ü 2: MODEL TRAINING")
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ train_global_model.py
    from train_global_model import (
        Config, 
        load_all_ticker_data, 
        create_target_variable,
        time_series_split,
        prepare_lgbm_data,
        train_quantile_models,
        save_models,
        plot_feature_importance,
        generate_validation_report
    )
    import gc
    
    start_time = time.time()
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        global_df = load_all_ticker_data(Config.DATA_DIR)
        
        # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        global_df = create_target_variable(global_df, horizon=Config.TARGET_HORIZON)
        
        # 3. –í—Ä–µ–º–µ–Ω–Ω–æ–π split
        train_df, test_df = time_series_split(global_df, Config.TRAIN_CUTOFF_DATE)
        
        del global_df
        gc.collect()
        
        # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LightGBM
        data = prepare_lgbm_data(
            train_df, test_df, 
            Config.TARGET_COL,
            Config.CATEGORICAL_FEATURES
        )
        
        del train_df, test_df
        gc.collect()
        
        # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        models = train_quantile_models(
            data,
            Config.QUANTILES,
            Config.LGBM_PARAMS,
            Config.NUM_BOOST_ROUND,
            Config.EARLY_STOPPING_ROUNDS
        )
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        save_models(models, Config.OUTPUT_MODEL_DIR)
        
        # 7. Feature Importance
        plot_feature_importance(models, Config.REPORTS_DIR, top_n=30)
        
        # 8. –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç
        generate_validation_report(models, data, Config.REPORTS_DIR)
        
        elapsed = time.time() - start_time
        print(f"\n‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {elapsed:.1f} —Å–µ–∫")
        print(f"‚úÖ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {Config.OUTPUT_MODEL_DIR}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_inference(ticker: str = "SBER", use_ensemble: bool = True):
    """
    –≠—Ç–∞–ø 3: Inference –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    
    –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞.
    """
    print_header("–≠–¢–ê–ü 3: INFERENCE & RESULTS")
    
    import pandas as pd
    import numpy as np
    from inference import GlobalQuantileModel, ENSEMBLE_AVAILABLE
    
    start_time = time.time()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print(f"üì¶ –†–µ–∂–∏–º: {'–ê–Ω—Å–∞–º–±–ª—å (LightGBM + GARCH)' if use_ensemble and ENSEMBLE_AVAILABLE else 'LightGBM'}")
    
    model = GlobalQuantileModel(
        use_ensemble=use_ensemble and ENSEMBLE_AVAILABLE,
        ensemble_weights={'lgbm': 0.7, 'garch': 0.3}
    )
    
    try:
        model.load_models()
    except FileNotFoundError as e:
        print(f"‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {e}")
        print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ —ç—Ç–∞–ø –æ–±—É—á–µ–Ω–∏—è (--skip-features)")
        return False
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    data_file = ML_ROOT / "data" / "processed_ml" / f"{ticker}_ml_features.parquet"
    
    if not data_file.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_file}")
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π —Ñ–∞–π–ª
        available = list((ML_ROOT / "data" / "processed_ml").glob("*_ml_features.parquet"))
        if available:
            data_file = available[0]
            ticker = data_file.stem.replace("_ml_features", "")
            print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º: {ticker}")
        else:
            print("   –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
            return False
    
    df = pd.read_parquet(data_file)
    print(f"\nüìä –î–∞–Ω–Ω—ã–µ: {ticker}, {len(df)} –∑–∞–ø–∏—Å–µ–π")
    
    # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 30 –¥–Ω—è—Ö
    n_predict = min(30, len(df))
    df_predict = df.tail(n_predict).copy()
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑
    if use_ensemble and ENSEMBLE_AVAILABLE:
        predictions = model.predict_ensemble(df_predict, return_components=True)
    else:
        predictions = model.predict(df_predict, return_interval=True)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—É –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    if 'date' in df_predict.columns:
        predictions['date'] = df_predict['date'].values
    
    elapsed = time.time() - start_time
    
    # === –†–ï–ó–£–õ–¨–¢–ê–¢–´ ===
    print_header("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–ì–ù–û–ó–ê")
    
    print(f"–¢–∏–∫–µ—Ä: {ticker}")
    print(f"–ü–µ—Ä–∏–æ–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–µ {n_predict} –¥–Ω–µ–π")
    print(f"–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {elapsed:.2f} —Å–µ–∫\n")
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã–≤–æ–¥
    display_cols = ['date'] if 'date' in predictions.columns else []
    display_cols += ['pred_q16', 'pred_q50', 'pred_q84', 'interval_width']
    
    if 'lgbm_q50' in predictions.columns:
        display_cols += ['lgbm_q50', 'garch_forecast']
    
    print("–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:")
    print("-" * 80)
    
    display_df = predictions[display_cols].tail(10).copy()
    
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    for col in display_df.columns:
        if col != 'date' and display_df[col].dtype in ['float64', 'float32']:
            display_df[col] = display_df[col].round(4)
    
    print(display_df.to_string(index=False))
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "-" * 80)
    print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:")
    print(f"   –ú–µ–¥–∏–∞–Ω–∞ (q50): {predictions['pred_q50'].mean():.4f} (mean), {predictions['pred_q50'].std():.4f} (std)")
    print(f"   –ò–Ω—Ç–µ—Ä–≤–∞–ª:      [{predictions['pred_q16'].mean():.4f}, {predictions['pred_q84'].mean():.4f}] (mean)")
    print(f"   –®–∏—Ä–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (mean): {predictions['interval_width'].mean():.4f}")
    
    # Feature Importance (—Ç–æ–ø-5)
    print("\nüìã –¢–æ–ø-5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏:")
    try:
        importance = model.get_feature_importance(top_n=5)
        for _, row in importance.iterrows():
            print(f"   ‚Ä¢ {row['feature']}: {row['importance']:.1f}")
    except Exception:
        print("   (–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ)")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = ML_ROOT / "data" / "models" / f"{ticker}_predictions.csv"
    predictions.to_csv(output_file, index=False)
    print(f"\nüíæ –ü—Ä–æ–≥–Ω–æ–∑—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    
    return True


def set_training_preset(preset_name: str):
    """
    –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–µ—Å–µ—Ç –≤ config/training_config.py.
    
    Args:
        preset_name: –ò–º—è –ø—Ä–µ—Å–µ—Ç–∞ (BASELINE, MORE_TRAIN, REGULARIZED, NO_TICKER)
    """
    config_file = ML_ROOT / "config" / "training_config.py"
    
    if not config_file.exists():
        print(f"‚ö†Ô∏è –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_file}")
        print("   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
        return False
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ó–∞–º–µ–Ω—è–µ–º ACTIVE_PRESET
        original_content = content
        content = re.sub(
            r"ACTIVE_PRESET = ['\"][^'\"]+['\"]",
            f"ACTIVE_PRESET = '{preset_name}'",
            content
        )
        
        if content != original_content:
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–µ—Å–µ—Ç: {preset_name}")
            return True
        else:
            print(f"‚ö†Ô∏è –ü—Ä–µ—Å–µ—Ç {preset_name} —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥–µ")
            return False
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –ø—Ä–µ—Å–µ—Ç–∞: {e}")
        return False


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    
    parser = argparse.ArgumentParser(
        description="MOEX Volatility Scanner - Full Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  python scripts/run_full_pipeline.py                    # –ü–æ–ª–Ω—ã–π pipeline
  python scripts/run_full_pipeline.py --preset MORE_TRAIN # –° –ø—Ä–µ—Å–µ—Ç–æ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
  python scripts/run_full_pipeline.py --skip-features   # –¢–æ–ª—å–∫–æ –æ–±—É—á–µ–Ω–∏–µ –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
  python scripts/run_full_pipeline.py --skip-training   # –¢–æ–ª—å–∫–æ features –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
  python scripts/run_full_pipeline.py --ticker GAZP      # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è GAZP
  python scripts/run_full_pipeline.py --no-intraday      # –ë–µ–∑ H1 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

–ü—Ä–µ—Å–µ—Ç—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–≤ config/training_config.py):
  - BASELINE: –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å (60/40 split)
  - MORE_TRAIN: –ë–æ–ª—å—à–µ train –¥–∞–Ω–Ω—ã—Ö (70/30 split)
  - REGULARIZED: –°–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
  - NO_TICKER: –ë–µ–∑ ticker_id –ø—Ä–∏–∑–Ω–∞–∫–∞
        """
    )
    
    parser.add_argument(
        "--preset",
        type=str,
        default=None,
        choices=["BASELINE", "MORE_TRAIN", "REGULARIZED", "NO_TICKER"],
        help="–ü—Ä–µ—Å–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ config/training_config.py (default: —Ç–µ–∫—É—â–∏–π)"
    )
    
    parser.add_argument(
        "--skip-features", 
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–∞–ø Feature Engineering"
    )
    parser.add_argument(
        "--skip-training",
        action="store_true", 
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–∞–ø –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"
    )
    parser.add_argument(
        "--ticker",
        type=str,
        default="SBER",
        help="–¢–∏–∫–µ—Ä –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (default: SBER)"
    )
    parser.add_argument(
        "--no-intraday",
        action="store_true",
        help="–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω—É—Ç—Ä–∏–¥–Ω–µ–≤–Ω—ã–µ (H1) –ø—Ä–∏–∑–Ω–∞–∫–∏"
    )
    parser.add_argument(
        "--no-ensemble",
        action="store_true",
        help="–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª—å (—Ç–æ–ª—å–∫–æ LightGBM)"
    )
    
    args = parser.parse_args()
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ—Å–µ—Ç –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    if args.preset:
        set_training_preset(args.preset)
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    print("\n" + "üöÄ" * 35)
    print("   MOEX VOLATILITY SCANNER - FULL PIPELINE")
    print("   " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    if args.preset:
        print(f"   üìå –ü—Ä–µ—Å–µ—Ç: {args.preset}")
    print("üöÄ" * 35)
    
    total_start = time.time()
    success = True
    
    # –≠—Ç–∞–ø 1: Feature Engineering
    if not args.skip_features:
        if not run_feature_engineering(include_intraday=not args.no_intraday):
            print("‚ö†Ô∏è Feature Engineering –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏")
            success = False
    else:
        print("\n‚è≠Ô∏è Feature Engineering –ø—Ä–æ–ø—É—â–µ–Ω (--skip-features)")
    
    # –≠—Ç–∞–ø 2: Model Training
    if not args.skip_training and success:
        if not run_model_training():
            print("‚ö†Ô∏è Model Training –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏")
            success = False
    else:
        if args.skip_training:
            print("\n‚è≠Ô∏è Model Training –ø—Ä–æ–ø—É—â–µ–Ω (--skip-training)")
    
    # –≠—Ç–∞–ø 3: Inference
    if success:
        run_inference(
            ticker=args.ticker,
            use_ensemble=not args.no_ensemble
        )
    
    # –ò—Ç–æ–≥–∏
    total_elapsed = time.time() - total_start
    
    print("\n" + "=" * 70)
    print(f"üèÅ PIPELINE –ó–ê–í–ï–†–®–Å–ù")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_elapsed:.1f} —Å–µ–∫ ({total_elapsed/60:.1f} –º–∏–Ω)")
    print(f"   –°—Ç–∞—Ç—É—Å: {'‚úÖ –£—Å–ø–µ—à–Ω–æ' if success else '‚ö†Ô∏è –° –æ—à–∏–±–∫–∞–º–∏'}")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    main()

